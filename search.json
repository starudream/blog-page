[{"title":"Root 环境下安装系统证书","url":"/2023/11/05/add-ca-cert-at-root/","content":"# htk-inject-system-cert.shset -e # Fail on error# Create a separate temp directory, to hold the current certificates# Without this, when we add the mount we can&#x27;t read the current certs anymore.mkdir -m 700 /data/local/tmp/htk-ca-copy# Copy out the existing certificatescp /system/etc/security/cacerts/* /data/local/tmp/htk-ca-copy/# Create the in-memory mount on top of the system certs foldermount -t tmpfs tmpfs /system/etc/security/cacerts# Copy the existing certs back into the tmpfs mount, so we keep trusting themmv /data/local/tmp/htk-ca-copy/* /system/etc/security/cacerts/# Copy our new cert in, so we trust that too# cp /data/local/tmp/c88f7ed0.0 /system/etc/security/cacerts/cp /data/misc/user/0/cacerts-added/* /system/etc/security/cacerts/# Update the perms &amp; selinux context labels, so everything is as readable as beforechown root:root /system/etc/security/cacerts/*chmod 644 /system/etc/security/cacerts/*chcon u:object_r:system_file:s0 /system/etc/security/cacerts/*# Delete the temp cert directory &amp; this script itselfrm -r /data/local/tmp/htk-ca-copy# rm $&#123;injectionScriptPath&#125;echo &quot;System cert successfully injected&quot;\n\n\nref: http://91fans.com.cn/post/certificate/#gsc.tab=0\n\n","categories":["技术"],"tags":["root","magisk"]},{"title":"无 Root 抓包 HTTPS 请求","url":"/2022/05/09/android-packet-capture-without-root/","content":"适用于 Android 12，理论上适配低版本。\n测试环境 MIUI13 Android 12。\n准备工作\nBlackBox\n\nTrustMeAlready\n\nVNET\n\n百度云 cn7g\n\n\n使用依次安装以上三个软件。\n打开 BlackBox，先点击右下角的加号，将需要抓包的软件和 TrustMeAlready 加入到虚拟机中，再点击右上角打开 软件设置。\n\n\n开启 启用Xposed框架。\n\n\n终止 BlackBox。\n\n\n再次打开 BlackBox 的 软件设置，打开 模块管理，点击右下角的加号，选择 TrustMeAlready，并勾选。\n\n\n打开 XNET，导出 CA 证书。\n\n\n进入设置，搜索证书，选择 CA 证书 进入，一般在 安全 &gt; 证书管理 中找到。\n\n\n然后选择 安装 CA 证书，成功后，可在用户栏下找到刚才导入的 VNETTECH 证书。\n\n\n最后回到 VNET 中，点击右下角的加号，开始抓包。\n\n\n进入 BlackBox，打开需要抓包的软件即可。\n","categories":["技术"],"tags":["xposed","blackbox"]},{"title":"自动创建 Gitalk 关联 Issue","url":"/2024/04/11/auto-create-gitalk-issue/","content":"在根目录创建文件夹 scripts，在文件夹中创建文件 gitalk-init.js，内容如下：\nconst axios = require(&quot;axios&quot;)const md5 = require(&quot;md5&quot;)const options = &#123;  owner: &quot;starudream&quot;,  repo: &quot;blog-page&quot;,  accessToken: &quot;&lt;&lt;placeholder&gt;&gt;&quot;,  labels: &quot;Gitalk,&quot;,&#125;const axiosGithub = axios.create(&#123;  baseURL: &quot;https://api.github.com&quot;,  headers: &#123;    &quot;Accept&quot;: &quot;application/json&quot;,  &#125;,&#125;)const getIssueByLabels = (id) =&gt; &#123;  return axiosGithub.get(`/repos/$&#123;options.owner&#125;/$&#123;options.repo&#125;/issues`, &#123;    headers: &#123;      Authorization: `token $&#123;options.accessToken&#125;`,    &#125;,    params: &#123;      labels: options.labels.concat(id),      t: Date.now(),    &#125;,  &#125;).then(res =&gt; &#123;    if (res &amp;&amp; res.data &amp;&amp; res.data.length) &#123;      return res.data[0]    &#125;    return null  &#125;)&#125;const createIssue = (title, body, id) =&gt; &#123;  return axiosGithub.post(`/repos/$&#123;options.owner&#125;/$&#123;options.repo&#125;/issues`, &#123;    title,    labels: options.labels.concat(id).split(&quot;,&quot;),    body: body,  &#125;, &#123;    headers: &#123;      Authorization: `token $&#123;options.accessToken&#125;`,    &#125;,  &#125;).then(res =&gt; &#123;    return res.data  &#125;)&#125;hexo.extend.generator.register(&quot;gitalk-init&quot;, locals =&gt; &#123;  locals.posts.each(post =&gt; &#123;    if (post.layout !== &quot;post&quot; || !post.published || !post.comments) return    const title = post.title + &quot; | &quot; + hexo.config.title    const path = &quot;/&quot; + post.path    const hash = md5(path)    getIssueByLabels(hash).then(res =&gt; &#123;      if (res) &#123;        console.log(`【$&#123;title&#125;】has existed`)        return      &#125;      createIssue(title, post.permalink, hash).then(res =&gt; &#123;        console.log(`【$&#123;title&#125;】has created`)      &#125;)    &#125;)  &#125;)&#125;)\n\n然后运行 hexo generate --force 即会自动执行 scripts 内脚本文件。\n","categories":["技术"],"tags":["hexo","gitalk","issue"]},{"title":"备份还原 ubuntu 镜像","url":"/2020/07/24/backup-and-restore-ubuntu-image/","content":"备份通过以下命令查看磁盘\ndiskutil list\n\n运行下面的命令进行打包，将 N 替换为上面查到的号码，等待完成即可。\nsudo dd bs=1m if=/dev/rdiskN of=ubuntu.img\n\n压缩一般来说，上面打包的生成的 .img 大小为 TF 卡容量，若写入小容量卡会发生错误，所以要清除无用的空间。\n如果是 linux 系统，可以跳过这一步，直接执行下方的命令，windows 以及 mac 可使用 docker 来执行。\ndocker run -it --rm --privileged -v $(pwd):/shrink ubuntu:20.04\n\napt updateapt install partedcd /shrink./pishrink.sh in.img out.img\n\n等待完成后，发现 .img 有明显的缩小。\n恢复sudo dd bs=1m if=ubuntu.img of=/dev/rdiskN\n\n\nDrewsif&#x2F;PiShrink\n\n","categories":["技术"],"tags":["ubuntu","raspberry pi","pishrink"]},{"title":"生成 GitLab EE 许可证","url":"/2020/01/19/crack-gitlab/","content":"基于 gitlab-ee:12.6.4-ee\n创建 ruby docker 镜像docker run -it --rm ruby /bin/bash\n\n生成许可证gem install gitlab-license\n\ncat &gt; license.rb\n\nrequire &quot;openssl&quot;require &quot;gitlab/license&quot;key_pair = OpenSSL::PKey::RSA.generate(2048)File.open(&quot;license_key&quot;, &quot;w&quot;) &#123; |f| f.write(key_pair.to_pem) &#125;public_key = key_pair.public_keyFile.open(&quot;license_key.pub&quot;, &quot;w&quot;) &#123; |f| f.write(public_key.to_pem) &#125;private_key = OpenSSL::PKey::RSA.new File.read(&quot;license_key&quot;)Gitlab::License.encryption_key = private_keylicense = Gitlab::License.newlicense.licensee = &#123;  &quot;Name&quot; =&gt; &quot;none&quot;,  &quot;Company&quot; =&gt; &quot;none&quot;,  &quot;Email&quot; =&gt; &quot;example@test.com&quot;,&#125;license.starts_at = Date.new(2020, 1, 1) # 开始时间license.expires_at = Date.new(2050, 1, 1) # 结束时间license.notify_admins_at = Date.new(2049, 12, 1)license.notify_users_at = Date.new(2049, 12, 1)license.block_changes_at = Date.new(2050, 1, 1)license.restrictions = &#123;  active_user_count: 10000,&#125;puts &quot;License:&quot;puts licensedata = license.exportputs &quot;Exported license:&quot;puts dataFile.open(&quot;GitLabBV.gitlab-license&quot;, &quot;w&quot;) &#123; |f| f.write(data) &#125;public_key = OpenSSL::PKey::RSA.new File.read(&quot;license_key.pub&quot;)Gitlab::License.encryption_key = public_keydata = File.read(&quot;GitLabBV.gitlab-license&quot;)$license = Gitlab::License.import(data)puts &quot;Imported license:&quot;puts $licenseunless $license  raise &quot;The license is invalid.&quot;endif $license.restricted?(:active_user_count)  active_user_count = 10000  if active_user_count &gt; $license.restrictions[:active_user_count]    raise &quot;The active user count exceeds the allowed amount!&quot;  endendif $license.notify_admins?  puts &quot;The license is due to expire on #&#123;$license.expires_at&#125;.&quot;endif $license.notify_users?  puts &quot;The license is due to expire on #&#123;$license.expires_at&#125;.&quot;endmodule Gitlab  class GitAccess    def check(cmd, changes = nil)      if $license.block_changes?        return build_status_object(false, &quot;License expired&quot;)      end    end  endendputs &quot;This instance of GitLab Enterprise Edition is licensed to:&quot;$license.licensee.each do |key, value|  puts &quot;#&#123;key&#125;: #&#123;value&#125;&quot;endif $license.expired?  puts &quot;The license expired on #&#123;$license.expires_at&#125;&quot;elsif $license.will_expire?  puts &quot;The license will expire on #&#123;$license.expires_at&#125;&quot;else  puts &quot;The license will never expire.&quot;end\n\nruby license.rb\n\n生成 GitLabBV.gitlab-license license_key license_key.pub 这三个文件。\n使用许可证用 license_key.pub 文件替换 /opt/gitlab/embedded/service/gitlab-rails/.license_encryption_key.pub。\nGitLabBV.gitlab-license 即是许可证，填入 $&#123;address&#125;/admin/license 地址并重启。\n修改等级--- /opt/gitlab/embedded/service/gitlab-rails/ee/app/models/license.rb+++ /opt/gitlab/embedded/service/gitlab-rails/ee/app/models/license.rb@@ -367,7 +367,7 @@  end  def plan-    restricted_attr(:plan).presence || STARTER_PLAN+    restricted_attr(:plan).presence || ULTIMATE_PLAN  end  def edition\n\n修改完成后使用 gitlab-ctl reconfigure 重新加载配置。\n参考\nhttps://www.rubydoc.info/gems/gitlab-license/1.0.0/file/README.md\n\n","categories":["技术"],"tags":["gitlab","crack"]},{"title":"使用 telepresence 调试 k8s 线上环境","url":"/2024/03/19/debug-with-telepresence/","content":"下载安装请看 官方文档\n需要注意的是文档内所用的版本是 Pro版，与 Github Release 中下载的 开源版 非同一版本。\n以下使用的版本为 v2.19.0 Pro版。\n安装在本机配置 Kubectl Context 并使用 kubectl config use-context dev 切换到指定集群，或者直接在线上服务器执行以下命令安装 Traffic Manager；\ntelepresence helm install\n\n安装参数请参考 ArtifactHub\n安装完成后 kubectl get pod -n ambassador 查看状态：\nNAME                                                READY   STATUS    RESTARTS   AGEtraffic-manager-ambassador-agent-56654cffd7-8qqdh   1/1     Running   0          46straffic-manager-5b77fb5-62lr4                       1/1     Running   0          46s\n\n连接集群telepresence connect --namespace biz # 指定 namespace\n\nLaunching Telepresence User DaemonLaunching Telepresence Root Daemon...Connected to context dev, namespace biz (https://10.x.x.x:6443)\n\ntelepresence list\n\nbill              : ready to intercept (traffic-agent not yet installed)\n\n拦截转发流量查看指定服务的 yaml 配置：\nkubectl get svc -n biz bill -o yaml\n\napiVersion: v1kind: Servicemetadata:  name: bill  namespace: bizspec:  clusterIP: 10.43.57.126  clusterIPs:  - 10.43.57.126  internalTrafficPolicy: Cluster  ipFamilies:  - IPv4  ipFamilyPolicy: SingleStack  ports:  - name: http    port: 80    protocol: TCP    targetPort: 10000  - name: grpc    port: 81    protocol: TCP    targetPort: 10000  selector:    app: bill  sessionAffinity: None  type: ClusterIP\n\n可以看到 bill 服务中监听了 10000 端口，所以拦截时指定 10000:10000（&lt;local port&gt;:&lt;remote port&gt;）：\ntelepresence intercept bill -p 10000:10000\n\nUsing Deployment bill   Intercept name         : bill   State                  : ACTIVE   Workload kind          : Deployment   Destination            : 127.0.0.1:10000   Service Port Identifier: port   Volume Mount Error     : sshfs is not installed on your local machine   Intercepting           : all TCP requests\n\nkubectl describe pod -n biz bill-779b9c6bf7-mdmv6\n\nInit Containers:  tel-agent-init:    Container ID:  containerd://a8c5d0eff4714d77b8299ebe698dfe7907f521524f8ca267e9a1c24958e3ed9d    Image:         docker.io/datawire/ambassador-telepresence-agent:1.14.5    Image ID:      docker.io/datawire/ambassador-telepresence-agent@sha256:3f6f3076b1eca26c460ef166993c3d9e7527fcc2a3d74709e01869a39cfebd91    Port:          &lt;none&gt;    Host Port:     &lt;none&gt;    Args:      agent-init    State:          Terminated      Reason:       Completed      Exit Code:    0      Started:      Tue, 19 Mar 2024 10:02:21 +0800      Finished:     Tue, 19 Mar 2024 10:02:21 +0800    Ready:          TrueContainers:  bill:    Container ID:   containerd://e43df533e5f3834fcb9d7f5b62bef63b6a01375a3d94cee3f2a5ef8c83592966    Image:          ...    Image ID:       ...    Port:           10000/TCP    Host Port:      0/TCP    State:          Running    Ready:          True  traffic-agent:    Container ID:  containerd://356cdc8b7f423871907778085f43804a5e6c19c98884b0342e88b073d4926c8a    Image:         docker.io/datawire/ambassador-telepresence-agent:1.14.5    Image ID:      docker.io/datawire/ambassador-telepresence-agent@sha256:3f6f3076b1eca26c460ef166993c3d9e7527fcc2a3d74709e01869a39cfebd91    Port:          9900/TCP    Host Port:     0/TCP    Args:      agent    State:          Running      Started:      Tue, 19 Mar 2024 10:02:22 +0800    Ready:          True\n\n然后访问远程集群地址 https://10.x.x.x:8888/bill/_health 可以看到流量已经转发到本地的 10000 端口。\n恢复telepresence leave bill # stop `bill` intercepttelepresence quit -s # stop all local telepresence daemons\n\nRef\nhttps://www.getambassador.io/docs/telepresence\n\n","categories":["技术"],"tags":["kubernetes","telepresence","intercept"]},{"title":"部署 Docker Registry","url":"/2023/07/21/deploy-docker-regsitry/","content":"docker run -d \\  --name registry \\  --restart always \\  -p 5000:5000 \\  -v &quot;$&#123;STORAGE_DATA_DIR&#125;/registry&quot;:/var/lib/registry \\  registry:2.8.2docker run -d \\  --name registry-ui \\  --restart always \\  -p 5001:80 \\  -e SINGLE_REGISTRY=true \\  -e SHOW_CONTENT_DIGEST=true \\  -e NGINX_PROXY_PASS_URL=&quot;http://$&#123;REGISTER_IP_ADDR&#125;:5000&quot; \\  joxit/docker-registry-ui:2.5.0\n","categories":["技术"],"tags":["docker","registry"]},{"title":"使用 GitHub Actions 部署 Hexo","url":"/2020/04/10/deploy-hexo-with-github-actions/","content":"首先需要在 GitHub 上建立两个仓库，一个 公有，一个 私有。\n公有 仓库用于存放 Hexo 生成的静态文件以部署 GitHub Pages。\n私有 仓库用于存放未经编译的 Hexo 文件。\n示例：starudream/blog-page 为我的 公有 仓库，starudream/blog 是我的 私有 仓库。\n然后在 https://github.com/settings/tokens 申请 PAT，并将其加入私有仓库的 Secrets。\n最后在 私有 仓库内创建文件 .github/workflows/deploy.yml，修改相应内容：\nname: Deployon:  push:    branches:      - masterjobs:  deploy:    name: Deploy    runs-on: ubuntu-latest    steps:      - name: Checkout        uses: actions/checkout@v2        with:          fetch-depth: 1      - name: Checkout Page        uses: actions/checkout@v2        with:          fetch-depth: 1          repository: starudream/blog-page          path: .deploy_git          token: $&#123;&#123; secrets.PAGE_PAT &#125;&#125;      - name: Cache        uses: actions/cache@v1        with:          path: node_modules          key: $&#123;&#123; runner.os &#125;&#125;-$&#123;&#123; hashFiles(&#x27;**/package.json&#x27;) &#125;&#125;      - name: Node        uses: actions/setup-node@v1        with:          node-version: 12      - name: Build        run: |          npm install hexo-cli -g &amp;&amp; npm install &amp;&amp; npm run build      - name: Deploy        run: |          rm -rf .deploy_git/* &amp;&amp; cp -rf public/* .deploy_git/          git config --global user.name starudream          git config --global user.email justwangsheng@qq.com          message=$(git log -1 --pretty=format:%s)          cd .deploy_git          git add -A          git commit -m &quot;$message&quot;          git push\n","categories":["技术"],"tags":["hexo","github"]},{"title":"部署 NFS 服务","url":"/2023/07/21/deploy-nfs-server/","content":"安装yum install nfs-utils\n\n配置\n/etc/exports\n\n/data/nfs/iso *(rw,sync,no_subtree_check,no_root_squash)\n\n\nman: https://linux.die.net/man/5/exports\n\n启动systemctl start nfs-server.servicesystemctl enable nfs-server.servicesystemctl status nfs-server.service\n","categories":["技术"],"tags":["nfs","server"]},{"title":"使用 ACME.sh 签发 SSL 泛域名证书","url":"/2020/04/10/deploy-ssl-with-acme/","content":"脚本~/.acme.sh/acme.sh \\  --debug \\  --issue \\  --dns dns_dp \\  -d *.starudream.cn~/.acme.sh/acme.sh \\  --debug \\  --install-cert \\  -d *.starudream.cn \\  --fullchain-file &#x27;/usr/local/openresty/nginx/conf/ssl/*.starudream.cn.crt&#x27; \\  --key-file &#x27;/usr/local/openresty/nginx/conf/ssl/*.starudream.cn.key&#x27; \\  --reloadcmd &#x27;service nginx reload&#x27;\n\nnginx 配置文件server &#123;  listen 80;  listen [::]:80;  listen 443 ssl http2;  listen [::]:443 ssl http2;  ssl_certificate /usr/local/openresty/nginx/conf/ssl/*.starudream.cn.crt;  ssl_certificate_key /usr/local/openresty/nginx/conf/ssl/*.starudream.cn.key;  ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;  ssl_ciphers TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:TLS13-AES-128-CCM-8-SHA256:TLS13-AES-128-CCM-SHA256:EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;  ssl_prefer_server_ciphers on;  ssl_session_timeout 10m;  ssl_session_cache builtin:1000 shared:SSL:10m;  ssl_buffer_size 1400;  add_header Strict-Transport-Security max-age=15768000;  ssl_stapling on;  ssl_stapling_verify on;  server_name test.starudream.cn;  access_log /data/wwwlogs/test.starudream.cn_nginx.log combined;  index index.html;  root /data/wwwroot/default;  if ($ssl_protocol = &quot;&quot;) &#123; return 301 https://$host$request_uri; &#125;&#125;\n\n参考\nhttps://github.com/acmesh-official/acme.sh\n\n","categories":["技术"],"tags":["acme","ssl","https"]},{"title":"使用 Docker 部署私有 Derper","url":"/2024/03/06/deploy-tailscale-derper-with-docker/","content":"自建 Tailscale 的 Derper 节点并开启认证，需要在 Derper 节点也安装 Tailscale 客户端。\nDocker Composeversion: &quot;3&quot;services:  tailscale:    image: tailscale/tailscale    container_name: tailscale    privileged: true    restart: always    volumes:      - &quot;./tailscale/data:/var/lib/tailscale&quot;      - &quot;./tailscale/tmp:/tmp&quot;      - &quot;/dev/net/tun:/dev/net/tun&quot;    cap_add:      - net_admin      - sys_module    environment:      TS_AUTHKEY: &quot;从 https://login.tailscale.com/admin/settings/keys 获取&quot;      TS_STATE_DIR: &quot;/var/lib/tailscale&quot;      TS_USERSPACE: &quot;false&quot;  derper:    image: starudream/derper    container_name: derper    restart: always    command: /tailscale/derper -a :80 -verify-clients    depends_on:      - tailscale    ports:      - &quot;3478:3478/udp&quot;    volumes:      - &quot;./tailscale/tmp:/var/run/tailscale&quot;\n\nDerper 的镜像请 于此 查看。\n当前版本 1.60.1 中 tailscaled.sock 在 var/run/tailscale/tailscaled.sock 只是一个指向 /tmp/tailscaled.sock 的链接。\nNginx不使用 Derper 内置 SSL 证书，使用 nginx 反向代理，需要注意 proxy_set_header Upgrade $http_upgrade; 开启 Websocket。\nserver &#123;  # ...  location / &#123;    proxy_pass http://derper:80;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header X-Real-PORT $remote_port;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    proxy_set_header X-Forwarded-Proto $scheme;    # websocket    proxy_http_version 1.1;    proxy_set_header Upgrade $http_upgrade;    proxy_set_header Connection $connection_upgrade;  &#125;&#125;\n\nAccess Controls最后在 https://login.tailscale.com/admin/acls/file 修改配置文件，添加 DERPMap 配置。\nOmitDefaultRegions 会忽略官方的 Derper 节点，自建建议开启以保护隐私。\n下面的配置文件示例，分成内网与公网两个配置，Tailscale 客户端会通过延迟自动选择使用内网还是公网。\nNodes 内详细配置请看 DERPNode。\n&#123;  // ... acls ssh\t&quot;derpMap&quot;: &#123;\t\t&quot;OmitDefaultRegions&quot;: true,\t\t&quot;Regions&quot;: &#123;\t\t\t&quot;900&quot;: &#123;\t\t\t\t&quot;RegionID&quot;:   900,\t\t\t\t&quot;RegionCode&quot;: &quot;private&quot;,\t\t\t\t&quot;Nodes&quot;: [\t\t\t\t\t&#123;\t\t\t\t\t\t&quot;Name&quot;:     &quot;private-aliyun&quot;,\t\t\t\t\t\t&quot;RegionID&quot;: 900,\t\t\t\t\t\t&quot;HostName&quot;: &quot;derper.52xckl.cn&quot;,\t\t\t\t\t\t&quot;IPV4&quot;:     &quot;内网ip 172.17.0.1&quot;,\t\t\t\t\t\t&quot;STUNPort&quot;: 3478,\t\t\t\t\t\t&quot;DERPPort&quot;: 443\t\t\t\t\t&#125;\t\t\t\t]\t\t\t&#125;,\t\t\t&quot;901&quot;: &#123;\t\t\t\t&quot;RegionID&quot;:   901,\t\t\t\t&quot;RegionCode&quot;: &quot;public&quot;,\t\t\t\t&quot;Nodes&quot;: [\t\t\t\t\t&#123;\t\t\t\t\t\t&quot;Name&quot;:     &quot;public-aliyun&quot;,\t\t\t\t\t\t&quot;RegionID&quot;: 901,\t\t\t\t\t\t&quot;HostName&quot;: &quot;derper.52xckl.cn&quot;,\t\t\t\t\t\t&quot;IPV4&quot;:     &quot;公网ip&quot;,\t\t\t\t\t\t&quot;STUNPort&quot;: 3478,\t\t\t\t\t\t&quot;DERPPort&quot;: 443\t\t\t\t\t&#125;\t\t\t\t]\t\t\t&#125;\t\t&#125;\t&#125;&#125;\n\nTestdocker exec -it tailscale tailscale netcheck\n\nReport:\t* UDP: true\t* IPv4: yes, 172.19.0.1:34143\t* IPv6: no, unavailable in OS\t* MappingVariesByDestIP: true\t* HairPinning: false\t* PortMapping:\t* Nearest DERP:\t* DERP latency:\t\t- private: 200µs   ()\t\t- public: 3.1ms   ()\n\ndocker exec -it tailscale tailscale ping &lt;node name&gt;\n\npong from &lt;node name&gt; (&lt;node ip&gt;) via DERP(public) in 11mspong from &lt;node name&gt; (&lt;node ip&gt;) via DERP(public) in 11mspong from &lt;node name&gt; (&lt;node ip&gt;) via DERP(public) in 11ms\n\nRef\nhttps://tailscale.com/kb/1118/custom-derp-servers\n\n","categories":["技术"],"tags":["docker"]},{"title":"使用 Docker 部署 TeamSpeak 3","url":"/2020/04/14/deploy-teamspeak/","content":"部署docker run -d \\    --name teamspeak \\    --restart always \\    -p 9987:9987/udp \\    -v /opt/docker/teamspeak:/var/ts3server \\    -e TS3SERVER_LICENSE=accept \\    -e TS3SERVER_SERVERADMIN_PASSWORD=PLACEHOLD \\    teamspeak:latest\n\n日志使用以下命令查看 Query Admin Account 相关登录用户密码以及 Privilege Key。\ndocker logs teamspeak\n","categories":["技术"],"tags":["docker","teamspeak"]},{"title":"Linux 禁用 IPV6","url":"/2020/04/15/disable-ipv6-linux/","content":"验证是否开启 ipv6# ifconfig -a | grep inet6inet6 fe80::42:b8ff:feb5:4214  prefixlen 64  scopeid 0x20&lt;link&gt;inet6 fe80::5054:ff:fec3:d3bb  prefixlen 64  scopeid 0x20&lt;link&gt;inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;\n\n出现 inet6 相关即为开启 ipv6。\n修改内核模块配置编辑 /etc/default/grub 文件并在 GRUB_CMDLINE_LINUX 中添加 ipv6.disable=1。\n如果是 Ubuntu 可能还有 GRUB_CMDLINE_LINUX_DEFAULT，同样也需要添加 ipv6.disable=1。\n# cat /etc/default/grub......GRUB_CMDLINE_LINUX=&quot;crashkernel=auto console=ttyS0 console=tty0 panic=5 net.ifnames=0 biosdevname=0 intel_idle.max_cstate=1 intel_pstate=disable&quot;......\n\n修改后为\n# cat /etc/default/grub......GRUB_CMDLINE_LINUX=&quot;crashkernel=auto console=ttyS0 console=tty0 panic=5 net.ifnames=0 biosdevname=0 intel_idle.max_cstate=1 intel_pstate=disable ipv6.disable=1&quot;......\n\n应用更改# CentOSgrub2-mkconfig -o /boot/grub2/grub.cfg# Ubuntuupdate-grub\n\n重启shutdown -r now\n","categories":["技术"],"tags":["ubuntu","centos","ipv6"]},{"title":"elk 常见问题","url":"/2024/02/19/elk-common-problem/","content":"common#!/usr/bin/env bashmethod=$1if [ -z &quot;$method&quot; ]; then  method=&quot;GET&quot;fipath=$2if [[ $path == *\\?* ]]; then  path=&quot;$path&amp;pretty&quot;else  path=&quot;$path?pretty&quot;ficurl -v -u &quot;elastic:p1ssw0rd&quot; -X &quot;$method&quot; -H &quot;Content-Type: application/json&quot; &quot;$&#123;@:2&#125;&quot; &quot;http://localhost:9200/$path&quot;\n\nindex setting./curl.sh PUT _index_template/logstash -d &#x27;&#123;  &quot;template&quot;: &#123;    &quot;settings&quot;: &#123;      &quot;index&quot;: &#123;        &quot;lifecycle&quot;: &#123;          &quot;name&quot;: &quot;90-days-default&quot;,          &quot;rollover_alias&quot;: &quot;90days&quot;        &#125;,        &quot;refresh_interval&quot;: &quot;5s&quot;,        &quot;number_of_replicas&quot;: &quot;0&quot;      &#125;    &#125;  &#125;,  &quot;index_patterns&quot;: [    &quot;logstash-*&quot;  ]&#125;&#x27;\n\nindex health is yellow./curl.sh PUT _settings -d &#x27;&#123;  &quot;index.number_of_replicas&quot;: 0&#125;&#x27;\n\nindex has exceeded [1000000] - maximum allowed to be analyzed for highlighting./curl.sh PUT _settings -d &#x27;&#123;  &quot;index.highlight.max_analyzed_offset&quot;: 100000000&#125;&#x27;\n\nthis action would add [2] shards, but this cluster currently has [1000]&#x2F;[1000]./curl.sh PUT _cluster/settings -d &#x27;&#123;  &quot;persistent&quot;: &#123;    &quot;cluster.max_shards_per_node&quot;: 1000000  &#125;&#125;&#x27;\n\nCan’t store an async search response larger than [10485760] bytes../curl.sh PUT _cluster/settings -d &#x27;&#123;  &quot;persistent&quot;: &#123;    &quot;search.max_async_search_response_size&quot;: &quot;50mb&quot;  &#125;&#125;&#x27;\n","categories":["技术"],"tags":["elasticsearch","kibana"]},{"title":"Envoy 配置导出 YAML 文件","url":"/2023/03/22/envoy-config-to-yaml/","content":"package mainimport (\t&quot;bytes&quot;\t&quot;encoding/json&quot;\t&quot;os&quot;\t&quot;testing&quot;\t&quot;gopkg.in/yaml.v3&quot;\t&quot;google.golang.org/protobuf/encoding/protojson&quot;\tbootstrap &quot;github.com/envoyproxy/go-control-plane/envoy/config/bootstrap/v3&quot;\tcluster &quot;github.com/envoyproxy/go-control-plane/envoy/config/cluster/v3&quot;\tcore &quot;github.com/envoyproxy/go-control-plane/envoy/config/core/v3&quot;\tlistener &quot;github.com/envoyproxy/go-control-plane/envoy/config/listener/v3&quot;)func TestGenBootstrapYAML(t *testing.T) &#123;\tcfg, err := initConfig(&quot;config.yaml&quot;)\tif err != nil &#123;\t\tt.Fatal(err)\t&#125;\tb := &amp;bootstrap.Bootstrap&#123;\t\tAdmin: &amp;bootstrap.Admin&#123;\t\t\tAccessLog: nil,\t\t\tAddress: &amp;core.Address&#123;\t\t\t\tAddress: &amp;core.Address_SocketAddress&#123;\t\t\t\t\tSocketAddress: &amp;core.SocketAddress&#123;\t\t\t\t\t\tAddress: &quot;0.0.0.0&quot;,\t\t\t\t\t\tPortSpecifier: &amp;core.SocketAddress_PortValue&#123;\t\t\t\t\t\t\tPortValue: 9901,\t\t\t\t\t\t&#125;,\t\t\t\t\t&#125;,\t\t\t\t&#125;,\t\t\t&#125;,\t\t&#125;,\t\tStaticResources: &amp;bootstrap.Bootstrap_StaticResources&#123;\t\t\tListeners: make([]*listener.Listener, 2),\t\t\tClusters:  make([]*cluster.Cluster, len(cfg.Clusters)),\t\t&#125;,\t&#125;\tvirtualHosts := genVirtualHosts(cfg)\tb.StaticResources.Listeners[0] = makeListener(ListenerHTTPPort, false, virtualHosts)\tb.StaticResources.Listeners[1] = makeListener(ListenerHTTPSPort, true, virtualHosts)\tfor i := 0; i &lt; len(cfg.Clusters); i++ &#123;\t\tb.StaticResources.Clusters[i] = makeCluster(cfg.Clusters[i])\t&#125;\tmo := protojson.MarshalOptions&#123;UseProtoNames: true&#125;\tbs, err := mo.Marshal(b)\tif err != nil &#123;\t\tt.Fatal(err)\t&#125;\tvar v any\terr = json.Unmarshal(bs, &amp;v)\tif err != nil &#123;\t\tt.Fatal(err)\t&#125;\tbb := &amp;bytes.Buffer&#123;&#125;\tye := yaml.NewEncoder(bb)\tye.SetIndent(2)\tdefer func() &#123; _ = ye.Close() &#125;()\terr = ye.Encode(v)\tif err != nil &#123;\t\tt.Fatal(err)\t&#125;\terr = os.WriteFile(&quot;envoy-bootstrap.yaml&quot;, bb.Bytes(), 0644)\tif err != nil &#123;\t\tt.Fatal(err)\t&#125;&#125;\n","categories":["技术"],"tags":["envoy","yaml"]},{"title":"通过 LUA 记录 Envoy 请求日志","url":"/2023/03/22/envoy-log-requesst-by-lua/","content":"function trim_prefix(s, p)    return (s:sub(0, #p) == p) and s:sub(#p + 1) or sendfunction envoy_on_request(request_handle)    local idx = 0    for chunk in request_handle:bodyChunks() do        local len = chunk:length()        if len == 0 then            break        end        local body = chunk:getBytes(idx, len)        idx = idx + len        local hds = &#123;&#125;        for key, value in pairs(request_handle:headers()) do            hds[&quot;y-&quot; .. trim_prefix(key, &quot;:&quot;)] = value        end        hds[&quot;:method&quot;] = &quot;POST&quot;        hds[&quot;:path&quot;] = &quot;/log&quot;        hds[&quot;:authority&quot;] = &quot;envoy&quot;        request_handle:httpCall(&quot;http-log-service&quot;, hds, body, 10000, true)    endendfunction envoy_on_response(response_handle)end\n\nstatic_resources:  clusters:    - name: http-log-service      type: STRICT_DNS      connect_timeout: 10s      load_assignment:        cluster_name: http-log-service        endpoints:          - lb_endpoints:              - endpoint:                  address:                    socket_address:                      address: 127.0.0.1                      port_value: 9709\n","categories":["技术"],"tags":["envoy","golang"]},{"title":"Envoy XDS","url":"/2023/03/22/envoy-xds/","content":"前言该篇文章所展示代码只展示大概思路，部分代码因为涉及到公司内部业务，所以没有展示出来。\n代码\nmain.go\n\npackage mainimport (\t&quot;context&quot;\t&quot;flag&quot;\t&quot;log&quot;\t&quot;net&quot;\t&quot;path/filepath&quot;\t&quot;google.golang.org/grpc&quot;\t&quot;github.com/google/uuid&quot;\t&quot;github.com/envoyproxy/go-control-plane/pkg/server/v3&quot;)var (\t_addr    string\t_config  string\tVERSION string\tBIDTIME string)func run(ctx context.Context) &#123;\tlog.Printf(&quot;version: %s, bidtime: %s&quot;, VERSION, BIDTIME)\tcfg, err := initConfig(_config)\tif err != nil &#123;\t\tlog.Fatalf(&quot;init config error: %s&quot;, err)\t&#125;\tprintConfig(cfg)\tgrpcServer := newGRPCServer()\tenvoyCache, envoyServer := newEnvoyServer(ctx)\tversion, err := uuid.NewRandom()\tif err != nil &#123;\t\tlog.Fatalf(&quot;generate version error: %s&quot;, err)\t&#125;\tsnapshot := genSnapshot(cfg, version.String())\terr = snapshot.Consistent()\tif err != nil &#123;\t\tlog.Fatalf(&quot;snapshot inconsistent: %s&quot;, err)\t&#125;\terr = envoyCache.SetSnapshot(ctx, cfg.Node, snapshot)\tif err != nil &#123;\t\tlog.Fatalf(&quot;set snapshot error: %s&quot;, err)\t&#125;\tlog.Printf(&quot;snapshot version: %s&quot;, version)\tgo func() &#123; runServer(_addr, grpcServer, envoyServer) &#125;()\ts := &lt;-sig\tlog.Printf(&quot;receive signal: %s&quot;, s)\tgrpcServer.Stop()\tlog.Printf(&quot;bye&quot;)\tclose(cls)&#125;func runServer(address string, grpcServer *grpc.Server, envoyServer server.Server) &#123;\tln, err := net.Listen(&quot;tcp&quot;, address)\tif err != nil &#123;\t\tlog.Fatalf(&quot;listen error: %s&quot;, err)\t&#125;\tregisterServer(grpcServer, envoyServer)\tlog.Printf(&quot;start grpc server success on %s&quot;, address)\terr = grpcServer.Serve(ln)\tif err != nil &#123;\t\tlog.Fatalf(&quot;serve error: %s&quot;, err)\t&#125;&#125;\n\n\nconfig.go\n\npackage maintype Config struct &#123;\tNode           string      `json:&quot;node,omitempty&quot; yaml:&quot;node&quot;`\tInclude        []string    `json:&quot;include,omitempty&quot; yaml:&quot;include&quot;`\tCors           *iCors      `json:&quot;cors,omitempty&quot; yaml:&quot;cors&quot;`\tRoutes         []*iRoute   `json:&quot;routes,omitempty&quot; yaml:&quot;routes&quot;`\tClusters       []*iCluster `json:&quot;clusters,omitempty&quot; yaml:&quot;clusters&quot;`\tTerminalDomain string      `json:&quot;terminal_domain&quot; yaml:&quot;terminal_domain&quot;`&#125;type iCors struct &#123;\tAllowMethods  []string `json:&quot;allow_methods,omitempty&quot; yaml:&quot;allow_methods&quot;`\tAllowHeaders  []string `json:&quot;allow_headers,omitempty&quot; yaml:&quot;allow_headers&quot;`\tExposeHeaders []string `json:&quot;expose_headers,omitempty&quot; yaml:&quot;expose_headers&quot;`&#125;type iRoute struct &#123;\tMatch               *iRouteMatch    `json:&quot;match,omitempty&quot; yaml:&quot;match&quot;`\tRoute               *iRouteRoute    `json:&quot;route,omitempty&quot; yaml:&quot;route&quot;`\tRequestHeadersToAdd []*iRouteHeader `json:&quot;request_headers_to_add,omitempty&quot; yaml:&quot;request_headers_to_add&quot;`&#125;type iRouteMatch struct &#123;\tPrefix string             `json:&quot;prefix,omitempty&quot; yaml:&quot;prefix&quot;`\tHeader *iRouteMatchHeader `json:&quot;header,omitempty&quot; yaml:&quot;header&quot;`&#125;type iRouteMatchHeader struct &#123;\tName       string `json:&quot;name,omitempty&quot; yaml:&quot;name&quot;`\tExactMatch string `json:&quot;exact_match,omitempty&quot; yaml:&quot;exact_match&quot;`\tRe2Match   string `json:&quot;re2_match,omitempty&quot; yaml:&quot;re2_match&quot;`&#125;type iRouteRoute struct &#123;\tCluster            string        `json:&quot;cluster,omitempty&quot; yaml:&quot;cluster&quot;`\tTimeout            time.Duration `json:&quot;timeout,omitempty&quot; yaml:&quot;timeout&quot;`\tPrefixRewrite      string        `json:&quot;prefix_rewrite,omitempty&quot; yaml:&quot;prefix_rewrite&quot;`\tHostRewriteLiteral string        `json:&quot;host_rewrite_literal,omitempty&quot; yaml:&quot;host_rewrite_literal&quot;`&#125;type iRouteHeader struct &#123;\tHeader *iKeyValue `json:&quot;header,omitempty&quot; yaml:&quot;header&quot;`&#125;type iKeyValue struct &#123;\tKey   string `json:&quot;key,omitempty&quot; yaml:&quot;key&quot;`\tValue string `json:&quot;value,omitempty&quot; yaml:&quot;value&quot;`&#125;type iCluster struct &#123;\tName     string `json:&quot;name,omitempty&quot; yaml:&quot;name&quot;`\tEndpoint string `json:&quot;endpoint,omitempty&quot; yaml:&quot;endpoint&quot;`\tHttp2    bool   `json:&quot;http2,omitempty&quot; yaml:&quot;http2&quot;`\tHttps    bool   `json:&quot;https,omitempty&quot; yaml:&quot;https&quot;`\tHost string `json:&quot;host,omitempty&quot; yaml:&quot;host&quot;`\tPort uint32 `json:&quot;port,omitempty&quot; yaml:&quot;port&quot;`&#125;\n\n\nserver.go\n\npackage mainimport (\t&quot;context&quot;\t&quot;time&quot;\t&quot;google.golang.org/grpc&quot;\t&quot;google.golang.org/grpc/keepalive&quot;\t&quot;github.com/envoyproxy/go-control-plane/pkg/cache/v3&quot;\t&quot;github.com/envoyproxy/go-control-plane/pkg/server/v3&quot;\tdiscovery &quot;github.com/envoyproxy/go-control-plane/envoy/service/discovery/v3&quot;)func newGRPCServer() *grpc.Server &#123;\tgrpcServer := grpc.NewServer(\t\tgrpc.MaxConcurrentStreams(1000000),\t\tgrpc.KeepaliveParams(keepalive.ServerParameters&#123;\t\t\tTime:    30 * time.Second,\t\t\tTimeout: 3 * time.Second,\t\t&#125;),\t\tgrpc.KeepaliveEnforcementPolicy(keepalive.EnforcementPolicy&#123;\t\t\tMinTime:             30 * time.Second,\t\t\tPermitWithoutStream: true,\t\t&#125;),\t)\treturn grpcServer&#125;func newEnvoyServer(ctx context.Context) (cache.SnapshotCache, server.Server) &#123;\tenvoyCache := cache.NewSnapshotCache(false, cache.IDHash&#123;&#125;, &amp;envoyLogger&#123;&#125;)\tenvoyServer := server.NewServer(ctx, envoyCache, nil)\treturn envoyCache, envoyServer&#125;func registerServer(grpcServer *grpc.Server, envoyServer server.Server) &#123;\tdiscovery.RegisterAggregatedDiscoveryServiceServer(grpcServer, envoyServer)&#125;\n\n\nresource.go\n\npackage mainimport (\t&quot;log&quot;\t&quot;strconv&quot;\t&quot;strings&quot;\t&quot;google.golang.org/protobuf/proto&quot;\t&quot;google.golang.org/protobuf/types/known/anypb&quot;\t&quot;google.golang.org/protobuf/types/known/durationpb&quot;\t&quot;google.golang.org/protobuf/types/known/wrapperspb&quot;\t&quot;github.com/envoyproxy/go-control-plane/pkg/cache/types&quot;\t&quot;github.com/envoyproxy/go-control-plane/pkg/cache/v3&quot;\t&quot;github.com/envoyproxy/go-control-plane/pkg/resource/v3&quot;\t&quot;github.com/envoyproxy/go-control-plane/pkg/wellknown&quot;\taccesslog &quot;github.com/envoyproxy/go-control-plane/envoy/config/accesslog/v3&quot;\tcluster &quot;github.com/envoyproxy/go-control-plane/envoy/config/cluster/v3&quot;\tcore &quot;github.com/envoyproxy/go-control-plane/envoy/config/core/v3&quot;\tendpoint &quot;github.com/envoyproxy/go-control-plane/envoy/config/endpoint/v3&quot;\tlistener &quot;github.com/envoyproxy/go-control-plane/envoy/config/listener/v3&quot;\troute &quot;github.com/envoyproxy/go-control-plane/envoy/config/route/v3&quot;\tfile &quot;github.com/envoyproxy/go-control-plane/envoy/extensions/access_loggers/file/v3&quot;\tgzip &quot;github.com/envoyproxy/go-control-plane/envoy/extensions/compression/gzip/compressor/v3&quot;\tcompressor &quot;github.com/envoyproxy/go-control-plane/envoy/extensions/filters/http/compressor/v3&quot;\tcors &quot;github.com/envoyproxy/go-control-plane/envoy/extensions/filters/http/cors/v3&quot;\tlua &quot;github.com/envoyproxy/go-control-plane/envoy/extensions/filters/http/lua/v3&quot;\trouter &quot;github.com/envoyproxy/go-control-plane/envoy/extensions/filters/http/router/v3&quot;\thcm &quot;github.com/envoyproxy/go-control-plane/envoy/extensions/filters/network/http_connection_manager/v3&quot;\ttls &quot;github.com/envoyproxy/go-control-plane/envoy/extensions/transport_sockets/tls/v3&quot;\thttp &quot;github.com/envoyproxy/go-control-plane/envoy/extensions/upstreams/http/v3&quot;\tmatcher &quot;github.com/envoyproxy/go-control-plane/envoy/type/matcher/v3&quot;)func genSnapshot(cfg *Config, version string) *cache.Snapshot &#123;\tvirtualHosts := genVirtualHosts(cfg)\tresources := map[resource.Type][]types.Resource&#123;\t\tresource.ListenerType: &#123;\t\t\tmakeListener(ListenerHTTPPort, false, virtualHosts),\t\t\tmakeListener(ListenerHTTPSPort, true, virtualHosts),\t\t&#125;,\t\tresource.ClusterType: genClusters(cfg.Clusters),\t&#125;\tsnap, err := cache.NewSnapshot(version, resources)\tif err != nil &#123;\t\tlog.Fatalf(&quot;failed to create snapshot: %s&quot;, err)\t&#125;\treturn snap&#125;...\n\nenvoy.yamldocker run -d --name envoy -v `pwd`/envoy.yaml:/etc/envoy/envoy.yaml -p 9901:9901 -p 10000:10000 envoyproxy/envoy:v1.23-latest\n\nadmin:  access_log_path: /tmp/admin_access.log  address:    socket_address: &#123; address: 0.0.0.0, port_value: 9901 &#125;node:  id: arc-os  cluster: arc-osdynamic_resources:  ads_config:    api_type: GRPC    transport_api_version: V3    grpc_services:      - envoy_grpc:          cluster_name: ads_cluster  cds_config:    resource_api_version: V3    ads: &#123; &#125;  lds_config:    resource_api_version: V3    ads: &#123; &#125;static_resources:  clusters:    - name: ads_cluster      connect_timeout: 30s      type: STRICT_DNS      lb_policy: ROUND_ROBIN      http2_protocol_options: &#123; &#125;      load_assignment:        cluster_name: ads_cluster        endpoints:          - lb_endpoints:              - endpoint:                  address:                    socket_address:                      address: 172.17.0.1                      port_value: 9777\n\nRef\nhttps://github.com/envoyproxy/go-control-plane\nhttps://github.com/envoyproxy/go-control-plane/blob/v0.11.0/internal/example/main/main.go\n\n","categories":["技术"],"tags":["envoy","golang"]},{"title":"win11 重装系统后找不到 explore.exe","url":"/2024/04/11/explore-exe-not-found-after-reinstall-win11/","content":"首先 Win+R 打开 运行\n然后 regedit 打开注册表，按 计算机\\HKEY_CLASSES_ROOT\\CLSID\\&#123;52205fd8-5dfb-447d-801a-d0b52f2e83e1&#125;\\shell\\OpenNewWindow\\command 目录找到 command\n右击依次选择 权限 -&gt; 高级 -&gt; 更改所有者 -&gt; 授予权限\n\n\n然后删除 command 目录下的 DelegateExecute 项\n将 (默认) 设置为 explorer.exe ::&#123;20D04FE0-3AEA-1069-A2D8-08002B30309D&#125;\n之后重启电脑即可，Win+E 也能使用了。\n","categories":["技术"],"tags":["windows"]},{"title":"配置 git@github.com 使用代理","url":"/2023/07/21/git-protocol-use-proxy/","content":"修改 ~/.ssh/config 文件，添加以下内容\nHost github.com    HostName github.com    ProxyCommand /usr/bin/nc -X connect -x 127.0.0.1:7890 %h %p\n\n如果出现 Connection closed by UNKNOWN port 65535 错误，说明当前代理服务器不支持，切换其他节点即可。\n","categories":["技术"],"tags":["git"]},{"title":"GitKraken Crack","url":"/2019/12/12/gitkraken-crack/","content":"安装 npm 以及 asar# download: https://nodejs.org/en/npm i -g asar\n\n解压 GitKraken 的资源文件# 安装目录\\gitkraken\\app-x.x.x\\resourcesasar extract ./app.asar ./tmp/\n\n修改 static&#x2F;index.js 文件（注意备份）下面是 v6.5.1 之后的版本\n--- static/index.js+++ static/index.js@@ -1,6 +1,27 @@ // Warning: You almost certainly do *not* want to edit this code - // instead, you want to edit src/js/main.jsx instead++function PatchSnapshot() &#123;+  const edmLiteD = snapshotResult.customRequire(&#x27;@axosoft/edm-lite-d/src/d.js&#x27;);+  snapshotResult.customRequire.cache[&#x27;@axosoft/edm-lite-d/src/d.js&#x27;] = &#123;+    exports: function() &#123;+      let response = JSON.parse(edmLiteD(...arguments).toString(&#x27;utf8&#x27;));+      if (&#x27;licenseExpiresAt&#x27; in response || &#x27;licensedFeatures&#x27; in response) &#123;+        response = &#123;+          ...response,+          availableTrialDays: null,+          licenseExpiresAt: 8640000000000000,+          licensedFeatures: [&#x27;pro&#x27;]+        &#125;;+      &#125;+      return Buffer.from(JSON.stringify(response), &#x27;utf8&#x27;);+    &#125;+  &#125;;+&#125;+ (function() &#123;+  PatchSnapshot();+   const Perf = snapshotResult.customRequire(&#x27;./src/js/utils/Performance.js&#x27;);   Perf.timeEnd(&#x27;loading monaco scripts&#x27;);   Perf.time(&#x27;index.js pre-bootstrap&#x27;);\n\n下面是 v6.5.1 之前的版本\n--- static/index.js+++ static/index.js@@ -1,7 +1,29 @@ // Warning: You almost certainly do *not* want to edit this code - // instead, you want to edit src/js/main.jsx instead+function XhrPromiseReduxProxy() &#123;+  const xhrPromiseRedux = snapshotResult.customRequire(+    &#x27;xhr-promise-redux/dist/index.js&#x27;+  );+  xhrPromiseRedux._post = xhrPromiseRedux.post;+  xhrPromiseRedux.post = async (url, options) =&gt; &#123;+    const res = await xhrPromiseRedux._post(url, options);+    if (url.match(/https:\\/\\/.*api.gitkraken.com\\/phone-home/)) &#123;+      res.body.availableTrialDays = null;+      res.body.code = 0;+      res.body.features = [];+      res.body.individualAccessState = null;+      res.body.licenseExpiresAt = 8640000000000000;+      res.body.licensedFeatures = [&#x27;pro&#x27;];+      res.body.proAccessState = null;+    &#125;+    return res;+  &#125;;+&#125;+ (function() &#123;+  XhrPromiseReduxProxy();+   const Perf = snapshotResult.customRequire(&#x27;./src/js/utils/Performance.js&#x27;);   Perf.timeEnd(&#x27;loading monaco scripts&#x27;);   Perf.time(&#x27;index.js pre-bootstrap&#x27;);\n\n重新打包asar pack ./tmp/ app.asar\n","categories":["技术"],"tags":["crack","gitkraken"]},{"title":"gitlab runner 使用 dind 作为 service 时的健康检查出错","url":"/2024/02/19/gitlab-dind-as-service-hc/","content":"解决不必要的 30s 超时等待时间\nFROM docker:20-dind as upstreamFROM scratchCOPY --from=upstream / /VOLUME /var/lib/dockerEXPOSE 2376ENV DOCKER_TLS_CERTDIR=/certsENTRYPOINT [&quot;dockerd-entrypoint.sh&quot;]CMD []\n\nRef\nhttps://gitlab.com/gitlab-org/gitlab-runner/-/issues/29130#note_1028331564\nhttps://github.com/docker-library/docker/blob/0d1c2100d12da2e7e458cdff18d741f625ce27d6/20.10/dind/Dockerfile\n\n","categories":["技术"],"tags":["docker","gitlab runner"]},{"title":"使用云效流水线功能实现 Go 私有库和 Proto 中心仓库自动发布","url":"/2024/11/13/goprivate-and-proto-publish-with-aliyun-devops/","content":"Proto &amp; Buf\nbuf.yaml\n\n# yaml-language-server: $schema=https://json.schemastore.org/buf.jsonversion: v2deps:  - buf.build/googleapis/googleapis  - buf.build/envoyproxy/protoc-gen-validate  - buf.build/grpc-ecosystem/grpc-gatewaylint:  use:    - BASIC  ignore_only:    IMPORT_NO_PUBLIC:      - common/common.protobreaking:  use:    - FILE\n\n\nbuf.gen.yaml\n\n# yaml-language-server: $schema=https://json.schemastore.org/buf.gen.jsonversion: v2plugins:  # https://github.com/protocolbuffers/protobuf-go  - local: protoc-gen-go    out: gen_go    opt:      - paths=source_relative  # https://github.com/grpc/grpc-go  - local: protoc-gen-go-grpc    out: gen_go    opt:      - paths=source_relative  # github.com/envoyproxy/protoc-gen-validate  - local: protoc-gen-validate    out: gen_go    opt:      - paths=source_relative      - lang=go  # github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway  # - local: protoc-gen-grpc-gateway  #   out: gen_go  #   opt:  #     - paths=source_relative  # github.com/go-kratos/kratos/cmd/protoc-gen-go-http/v2  - local: protoc-gen-go-http    out: gen_go    opt:      - paths=source_relative  # github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2  - local: protoc-gen-openapiv2    strategy: all    out: gen_doc    opt:      - allow_merge=true      - include_package_in_tags=true      - fqn_for_openapi_name=true      - use_go_templates=true      - disable_default_errors=true      - enums_as_ints=true      - output_format=yaml      - preserve_rpc_order=true\n\n流水线服务连接管理\n\n构建集群\n\n生成并发布 Proto将 api-pb 所生成的 go 代码推送至 api-go 仓库，以便 goprivate 使用。\ndefaultWorkspace: api_pbsources:  api_pb:    type: codeup    endpoint: git@codeup.aliyun.com:starudream/os/api-pb.git    certificate:      type: serviceConnection      serviceConnection: $&#123;云效Codeup服务连接ID&#125;    triggerEvents:      - push  api_go:    type: codeup    endpoint: git@codeup.aliyun.com:starudream/os/api-go.git    certificate:      type: serviceConnection      serviceConnection: $&#123;云效Codeup服务连接ID&#125;    triggerEvents:      - tagPush # 防止 push 时触发该工作流stages:  proto:    jobs:      gen:        timeoutMinutes: 30        runsOn:          group: private/$&#123;私有构建集群ID&#125;        steps:          gen:            step: CustomEnvironmentBuild            with:              image: registry.cn-shanghai.aliyuncs.com/starudream/go-dev              privateRegistry: true              certificate:                type: serviceConnection                serviceConnection: $&#123;ACR服务连接ID&#125;              run: |                go version                buf --version                make clean gen                tar -czf pb_gen_$&#123;PIPELINE_ID&#125;_$&#123;BUILD_NUMBER&#125;.tar.gz gen_go gen_doc                mkdir -p /cache/proto/ &amp;&amp; mv -f pb_gen_$&#123;PIPELINE_ID&#125;_$&#123;BUILD_NUMBER&#125;.tar.gz /cache/proto/      pub:        timeoutMinutes: 30        runsOn:          group: private/$&#123;私有构建集群ID&#125;          vm: true        needs: gen        steps:          go:            step: Command            with:              run: |                pushd /data/yunxiao/cache/proto/ &gt;/dev/null                rm -rf $&#123;PIPELINE_ID&#125;_$&#123;BUILD_NUMBER&#125; &amp;&amp; mkdir -p $&#123;PIPELINE_ID&#125;_$&#123;BUILD_NUMBER&#125;                tar -xzf pb_gen_$&#123;PIPELINE_ID&#125;_$&#123;BUILD_NUMBER&#125;.tar.gz -C $&#123;PIPELINE_ID&#125;_$&#123;BUILD_NUMBER&#125;                mv -f $&#123;WORK_SPACE&#125;/api_go/.git $&#123;PIPELINE_ID&#125;_$&#123;BUILD_NUMBER&#125;/gen_go/.git                pushd $&#123;PIPELINE_ID&#125;_$&#123;BUILD_NUMBER&#125;/gen_go &gt;/dev/null                git config --global user.name &quot;ci-bot&quot;                git config --global user.email &quot;ci-bot@mail.starudream.cn&quot;                git add . &amp;&amp; git commit -m &quot;$&#123;CI_COMMIT_ID_1&#125; -&gt; $&#123;CI_COMMIT_TITLE_1&#125;&quot; &amp;&amp; git push                popd &gt;/dev/null                rm -rf $&#123;PIPELINE_ID&#125;_$&#123;BUILD_NUMBER&#125;\n\n\n\nGoPrivateConfigurationgo env -w CGO_ENABLED=0go env -w GO111MODULE=ongo env -w GOPRIVATE=codeup.aliyun.comgo env -w GOPROXY=https://goproxy.cn,direct\n\nssh keyreplace codeup.aliyun.com/starudream/os/api-go =&gt; codeup.aliyun.com/starudream/os/api-go.git\n\n需要手动指定版本，不能更新，比较麻烦。\nnetrc\nwindows: $HOME/_netrc\nlinux: $HOME/.netrc\n\n可以使用 go get -u 自动更新。\nBackendmodule codeup.aliyun.com/starudream/os/backendgo 1.23.0require (\tcodeup.aliyun.com/starudream/os/api-go v0.0.0-20241111023212-d66b05b24117\tcodeup.aliyun.com/starudream/os/lib-go v0.0.0-20241111082247-43cf457f0683)\n","categories":["技术"],"tags":["aliyun","devops","flow"]},{"title":"配置 Gradle 镜像","url":"/2024/06/26/gradle-mirror/","content":"~/.gradle/init.gradleallprojects &#123;    buildscript &#123;        repositories &#123;            maven &#123; url &#x27;https://maven.aliyun.com/repository/gradle-plugin/&#x27; &#125;            mavenLocal()        &#125;    &#125;    repositories &#123;        maven &#123; url &#x27;https://maven.aliyun.com/repository/public/&#x27; &#125;        maven &#123; url &#x27;https://maven.aliyun.com/repository/spring/&#x27; &#125;        mavenLocal()    &#125;&#125;\n\nbuild.gradlebuildscript &#123;    repositories &#123;        maven &#123; url &#x27;https://maven.aliyun.com/repository/gradle-plugin&#x27; &#125;        mavenLocal()    &#125;&#125;repositories &#123;  maven &#123; url &#x27;https://maven.aliyun.com/repository/public&#x27; &#125;  maven &#123; url &#x27;https://maven.aliyun.com/repository/spring&#x27; &#125;  mavenLocal()&#125;\n","categories":["技术"],"tags":["java","gradle"]},{"title":"基于 Gradle 构建 spring-boot-thin-launcher","url":"/2024/06/26/gradle-spring-thin/","content":"build.gradleplugins &#123;    id &#x27;java&#x27;    id &#x27;maven-publish&#x27;    id &#x27;org.springframework.boot&#x27; version &#x27;3.3.1&#x27;    id &#x27;io.spring.dependency-management&#x27; version &#x27;1.1.5&#x27;    id &#x27;org.springframework.boot.experimental.thin-launcher&#x27; version &#x27;1.0.31.RELEASE&#x27;&#125;bootJar &#123;  archiveFileName = &quot;$&#123;project.name&#125;.jar&quot;&#125;thinJar &#123;  archiveFileName = &quot;$&#123;project.name&#125;-thin.jar&quot;&#125;thinResolvePrepare &#123;  delete file(&#x27;thin&#x27;)  into file(&#x27;thin&#x27;)&#125;publishing &#123;  publications &#123;    maven(MavenPublication) &#123;      from components.java    &#125;  &#125;&#125;generatePomFileForMavenPublication &#123;  destination = file(&#x27;pom.xml&#x27;)&#125;\n\n生成 pom.xml./gradlew generatePomFileForMavenPublication\n\n编译生成 thin jar 包./gradlew clean thinResolvePrepare\n\n缓存 maven 依赖./mvnw dependency:resolve\n\n生成 thin jar 依赖结构java -Dthin.dryrun=true -Dthin.root=thin -Dthin.repo=https://maven.aliyun.com/repository/public -jar thin/$&#123;project.name&#125;-thin.jar\n\n可能需要的命令rsync -avzh thin/repository/ server:/opt/project/repository/scp thin/$&#123;project.name&#125;-thin.jar server:/opt/project/$&#123;project.name&#125;.jar\n","categories":["技术"],"tags":["java","gradle"]},{"title":"小米笔记本 Air 安装黑苹果","url":"/2021/11/01/hack-mac-in-mi-notebook-air-gen1/","content":"该教程适用于 2016 年小米笔记本 Air 13.3，CPU 为 i5-6200U\n与 2021-10-31 日测试安装 MacOS Big Sur 11.6 成功\n制作 MacOS 镜像可以参考上一篇文章下载官方的安装镜像。\n或者使用其他人修改过的镜像，比如 黑果小兵 MacOS 11.6 ，然后使用 etcher 制作镜像。\n替换 EFI 文件从 GitHub 上下载最新的代码，将其中的 EFI 文件拷贝到刚才制作完成镜像的 U 盘中，覆盖 其中的 EFI 文件夹。\n升级 BIOS 至 A06首先不插入 U 盘，开机按 F2 进入 BIOS 设置页面，查看当前 BIOS 版本，如果是 A05 需要将 BIOS 升级，如果是 A06 则无需升级进行下一步。\n从 百度云 ，提取码 z7ec 下载 VFBI0A06.zip 文件拷贝至 U 盘。\n重新启动，进入 Windows PE 系统，运行其中的可执行文件，电脑会自动重启并升级 BIOS。升级完成后重新启动 F2 进入 BIOS 设置页面查看对应版本是否是 A06。\n解锁 CFG LOCK插入 U 盘，开机按 F12，选择 U 盘进入界面后，选择 Modified GRUB Shell，首先 setup_var 0x84A 查看当前是否开启 CFG LOCK，在输出中有 0x01 则需要输入 setup_var 0x84A 0x00 进行解锁。\n安装 MacOS重新启动，按 F12 选择 Install MacOS Big Sur 进入。\n首先选择 磁盘工具 将内置磁盘格式化为 APFS，然后返回开始安装，在安装过程中会自动重启几次，在开机启动项中选择对应的启动项继续，直至见到 MacOS 配置页面，完成配置后进入系统。\n拷贝 EFI 至笔记本打开终端，输入 diskutil list 查看磁盘列表，一般来说 /dev/disk0s1 都是一个名为 EFI 的磁盘。\n使用 sudo diskutil mount /dev/disk0s1 命令挂载该磁盘。将上面拷贝至 U 盘 EFI 文件夹的内容同样拷贝到该磁盘。\n退出 U 盘，重新启动，如果能正确引导进入系统则安装成功。\n如果无法进入系统，重新插入 U 盘，重新配置引导文件。\n参考连接\nhttps://github.com/whtiehack/XiaoMi-Air\nhttps://github.com/sakoula/XiaoMi-Air-6200U\nhttps://github.com/johnnync13/Xiaomi-Notebook-Air-1Gen\nhttps://blog.daliansky.net\n\n","categories":["技术"],"tags":["mi","mac"]},{"title":"在 HTTPS 的反向代理 Nginx 后运行 HTTP Harbor","url":"/2022/05/18/harbor-behind-nginx-reverse-proxy/","content":"以下基于 Harbor v2.5.0。\n最终看起来像这样 nginx (host,ssl) -&gt; harbor-nginx (non-ssl) -&gt; harbor。\n说明首先服务上安装有 nginx，且配置了 SSL，现在可能在本机或者内网的其他机器上安装有 Harbor，需要反向代理到本机映射出去。\nharbor.yml首先需要注释掉 https 相关的配置，并添加 external_url 的配置项。\n# Configuration file of Harbor# The IP address or hostname to access admin UI and registry service.# DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.hostname: hub.example.cn# http related confighttp:  # port for http, default is 80. If https enabled, this port will redirect to https port  port: 5080# https related config# https:  # https port for harbor, default is 443  # port: 443  # The path of cert and key files for nginx  # certificate: /your/certificate/path  # private_key: /your/private/key/path# # Uncomment following will enable tls communication between all harbor components# internal_tls:#   # set enabled to true means internal tls is enabled#   enabled: true#   # put your cert and key files on dir#   dir: /etc/harbor/tls/internal# Uncomment external_url if you want to enable external proxy# And when it enabled the hostname will no longer usedexternal_url: https://hub.example.cn\n\nharbor.conf在 nginx 的 vhost 中新增相关配置，必须要配置 X-Forwarded-Proto $scheme，client_max_body_size 按需配置。\nserver &#123;    listen       80;    server_name  hub.example.cn;    location / &#123;        return 301 https://$host$request_uri;    &#125;&#125;server &#123;    listen       443 ssl http2;    server_name  hub.example.cn;    ssl_certificate      /usr/local/openresty/nginx/conf/ssl/hub.example.cn.crt;    ssl_certificate_key  /usr/local/openresty/nginx/conf/ssl/hub.example.cn.key;    client_max_body_size 500m;    location / &#123;        proxy_pass http://10.0.4.10:5080;        proxy_set_header Host $host;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Real-PORT $remote_port;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        proxy_set_header X-Forwarded-Proto $scheme;    &#125;&#125;\n\n常见问题docker login 出现 unauthorized: authentication requiredharbor 内没有配置 external_url。\n访问 hub.example.cn 会重定向到某个端口harbor 内需要取消 https 的配置。\ndocker push 出现 400 The plain HTTP request was sent to HTTPS port反向代理 nginx 中没有配置 X-Forwarded-Proto $scheme。\n","categories":["技术"],"tags":["docker","harbor","nginx"]},{"title":"安装 docker registry","url":"/2024/11/13/install-docker-registry/","content":"docker-compose.yamlservices:  registry:    image: registry:2.8.3    container_name: registry    restart: always    environment:      - TZ=Asia/Shanghai    volumes:      - &quot;$&#123;COMPOSE_DATA_DIR:-/data&#125;/registry:/var/lib/registry&quot;    ports:      - &quot;5000:5000&quot;  registry-ui:    image: joxit/docker-registry-ui:2.5.7    container_name: registry-ui    restart: always    depends_on:      - registry    environment:      - TZ=Asia/Shanghai      - SINGLE_REGISTRY=true      - SHOW_CONTENT_DIGEST=true      - PULL_URL=http://hub.starudream.local      - NGINX_PROXY_PASS_URL=http://registry:5000    ports:      #- &quot;80:80&quot;      - &quot;5001:80&quot;\n\nregistry-ui 默认附带一个 nginx，反向代理了 registry，如果没有其他网关可以设置为 80 端口直接使用。\nnginx 反代配置http &#123;    server &#123;        listen 8080;        location /v2/ &#123;            proxy_pass http://10.252.25.215:5000;            proxy_set_header Host $host;            proxy_set_header X-Real-IP $remote_addr;            proxy_set_header X-Real-PORT $remote_port;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Forwarded-Proto $scheme;        &#125;        location /registry/ &#123;            proxy_pass http://10.252.25.215:5001/;        &#125;    &#125;&#125;\n","categories":["技术"],"tags":["docker","registry"]},{"title":"安装 Docker","url":"/2020/05/09/install-docker/","content":"下载安装脚本curl -fsSL https://get.docker.com -o get-docker.sh\n\n设置安装版本（nightly &#x2F; test &#x2F; stable）export CHANNEL=stable\n\n设置下载镜像源具体参考安装机器的 repo\n阿里云公网export DOWNLOAD_URL=https://mirrors.aliyun.com/docker-ce\n\n阿里云内网export DOWNLOAD_URL=http://mirrors.cloud.aliyuncs.com/docker-ce\n\n设置 repo 文件名export REPO_FILE=docker-ce.repo\n\n安装sh get-docker.sh\n\n配置mkdir -p /etc/dockercat &lt;&lt;EOF &gt;  /etc/docker/daemon.json&#123;    &quot;exec-opts&quot;: [        &quot;native.cgroupdriver=systemd&quot;    ],    &quot;registry-mirrors&quot;: [        &quot;http://f1361db2.m.daocloud.io&quot;    ],    &quot;log-driver&quot;: &quot;json-file&quot;,    &quot;log-opts&quot;: &#123;        &quot;max-size&quot;: &quot;100m&quot;    &#125;,    &quot;storage-driver&quot;: &quot;overlay2&quot;,    &quot;storage-opts&quot;: [        &quot;overlay2.override_kernel_check=true&quot;    ]&#125;EOF\n\n运行systemctl enable docker.servicesystemctl start docker.servicedocker version\n\n其他腾讯云镜像 repo 内地址仍是 download.docker.com ，所以使用该脚本没有效果，但是可以使用阿里云公网下载完成后替换镜像源\n# 替换为腾讯云内网sed -i &#x27;s|https://mirrors.aliyun.com|http://mirrors.tencentyun.com|&#x27; /etc/yum.repos.d/docker-ce.repo\n","categories":["技术"],"tags":["docker"]},{"title":"基于 Docker 安装 Gitea 和 Drone / Drone-Runner","url":"/2020/05/26/install-gitea-and-drone/","content":"安装 docker 并拉取相关镜像\ngitea&#x2F;gitea\n\ndrone&#x2F;drone\n\ndrone&#x2F;drone-runner-docker\n\n\ndocker pull gitea/giteadocker pull drone/dronedocker pull drone/drone-runner-docker\n\n安装 giteadocker run -d \\    --name gitea \\    --restart always \\    -p 53022:22 \\    -p 53080:3000 \\    -m 400m \\    -v /opt/docker/gitea/data:/data \\    gitea/gitea:1.11.5\n\n按照步骤完成安装 Gitea 后，打开 https://git.52xckl.cn/user/settings/applications 页面。\n应用名称：drone，重定向 URL：https://drone.52xckl.cn/login 填写完成后点击创建应用获取 客户端 ID 与 客户端密钥。\n创建 drone 与 drone-runner\n$&#123;CLIENT_ID&#125; -&gt; 客户端 ID\n$&#123;CLIENT_SECRET&#125; -&gt; 客户端密钥\n$&#123;RPC_SECRET&#125; -&gt; drone 与 drone-runner 通讯的密钥，随机生成即可\n\ndocker run -d \\    --name drone \\    --restart always \\    -m 200m \\    -p 54080:80 \\    -e DRONE_GITEA_SERVER=https://git.52xckl.cn \\    -e DRONE_GITEA_CLIENT_ID=$&#123;CLIENT_ID&#125; \\    -e DRONE_GITEA_CLIENT_SECRET=$&#123;CLIENT_SECRET&#125;= \\    -e DRONE_RPC_SECRET=$&#123;RPC_SECRET&#125; \\    -e DRONE_SERVER_HOST=drone.52xckl.cn \\    -e DRONE_SERVER_PROTO=https \\    -v /opt/docker/drone/data:/var/lib/drone \\    drone/drone:1.7.0\n\ndocker run -d \\    --name drone-runner \\    --link drone:drone \\    --restart always \\    -m 200m \\    -e DRONE_RUNNER_NAME=runner-001 \\    -e DRONE_RPC_PROTO=http \\    -e DRONE_RPC_HOST=drone \\    -e DRONE_RPC_SECRET=$&#123;RPC_SECRET&#125; \\    -v /var/run/docker.sock:/var/run/docker.sock \\    drone/drone-runner-docker:1.3.0\n\n最后 docker logs -f --tail 10 drone-runner 显示 successfully pinged the remote server 即为成功。\n测试首先打开 https://drone.52xckl.cn/ 完成 OAuth2 认证并激活项目。\n在激活的项目中创建名为 .drone.yml 的文件：\nkind: pipelinename: testtype: dockersteps:  - name: test    image: golang:1.14-alpine    commands:      - CGO_ENABLED=0 GO111MODULE=on go test -count=1 -cover -v ./...      - CGO_ENABLED=0 GO111MODULE=on go run .\n\n这段是 Go 相关项目的，如果编写该文件请查询相关官方文档。\n参考文档\ngitea\n\ndrone\n\n\n","categories":["技术"],"tags":["gitea","drone","drone-runner"]},{"title":"基于 Docker 安装 GitLab 和 GitLab-Runner","url":"/2019/12/13/install-gitlab-and-gitlab-runner/","content":"安装 docker 并拉取相关镜像\ngitlab&#x2F;gitlab-ce\n\ngitlab&#x2F;gitlab-runner\n\n\ndocker pull gitlab/gitlab-cedocker pull gitlab/gitlab-runner\n\n运行 docker 镜像\nGitLab CE\n\ndocker run -d \\    --name gitlab \\    --restart always \\    -p 127.0.0.1:50080:80 \\    -p 127.0.0.1:50022:22 \\    -m 2048m \\    -v /opt/docker/gitlab/config:/etc/gitlab \\    -v /opt/docker/gitlab/logs:/var/log/gitlab \\    -v /opt/docker/gitlab/data:/var/opt/gitlab \\    gitlab/gitlab-ce:latest\n\ndocker run -d \\    --name gitlab-runner \\    --link gitlab:gitlab \\    --restart always \\    -m 1024m \\    -v /var/run/docker.sock:/var/run/docker.sock \\    -v /opt/docker/gitlab-runner/config:/etc/gitlab-runner \\    gitlab/gitlab-runner:latest\n\n\nGitLab EE\n\ndocker run -d \\    --name gitlab \\    --restart always \\    -p 127.0.0.1:50080:80 \\    -p 127.0.0.1:50022:22 \\    -m 2048m \\    -v /opt/docker/gitlab/config:/etc/gitlab \\    -v /opt/docker/gitlab/logs:/var/log/gitlab \\    -v /opt/docker/gitlab/data:/var/opt/gitlab \\    -v /opt/docker/gitlab/.license_encryption_key.pub:/opt/gitlab/embedded/service/gitlab-rails/.license_encryption_key.pub \\    gitlab/gitlab-ee:latest\n\n注册 gitlab-runnerdocker exec -it gitlab-runner gitlab-runner register# 之后访问地址 http://code.52xckl.cn/admin/runners 配置即可# 配置地址可以使用 http://gitlab 内网\n\n参考文档\ngitlab\n\ngitlab-runner\n\n\n","categories":["技术"],"tags":["gitlab"]},{"title":"在 k8s 上使用 istio 管控","url":"/2020/05/14/install-istio-with-k8s/","content":"使用上一篇文章成功安装 k8s 和 calico 后，使用 istio 管控微服务。\n下载 istio\nhttps://istio.io/docs/setup/getting-started/\n\nIstio 1.5.4\n\n\ncurl -L https://istio.io/downloadIstio | sh -# 或者从 `https://github.com/istio/istio/releases/latest` 选择版本下载后解压 `tar zxf istio-*.tar.gz`cd istio-*# 并将目录下 bin 的路径加入环境变量 `PATH`export PATH=$PWD/bin:$PATH\n\n安装\nhttps://istio.io/docs/setup/install/istioctl/\n\n使用默认配置安装\nistioctl manifest apply\n\n验证是否安装成功\nistioctl manifest generate &gt; istio.yamlistioctl verify-install -f istio.yaml\n\n部署这里简单地引用了 gitea 作为部署镜像，若为微服务，修改相应路由即可。\n创建 test namespaceskubectl create namespace test\n\n创建 configmaps# config.yamlapiVersion: v1kind: ConfigMapmetadata:  name: config  namespace: testdata:  DB_TYPE: sqlite3\n\nkubectl apply -f config.yaml\n\n部署# gitea.yamlapiVersion: v1kind: Servicemetadata:  name: web  namespace: testspec:  type: ClusterIP  ports:    - name: http-web      port: 80      targetPort: 3000  selector:    app: web---apiVersion: apps/v1kind: Deploymentmetadata:  name: web  namespace: testspec:  replicas: 1  selector:    matchLabels:      app: web  template:    metadata:      labels:        app: web    spec:      containers:        - name: test          image: gitea/gitea:latest          ports:            - name: port              containerPort: 3000          envFrom:            - configMapRef:                name: config---apiVersion: networking.istio.io/v1beta1kind: VirtualServicemetadata:  name: web  namespace: testspec:  hosts:    - &quot;*&quot;  gateways:    - istio-system/istio-ingressgateway  http:    - match:        - uri:            prefix: &quot;/&quot;      route:        - destination:            host: web            port:              number: 80\n\nkubectl apply -f gitea.yaml\n\n查看修改 istio-ingressgateway 的 LoadBalancer 为 NodePort 将端口暴露出去。\nkubectl edit service istio-ingressgateway -n istio-system\n\nkubectl get service -n istio-system\n\nistio-ingressgateway   NodePort    10.96.203.60    &lt;none&gt;        80:31893/TCP   25m\n\n最后访问 http://$&#123;ip&#125;:31893/ 就可以看到 Gitea 的页面了。\n","categories":["技术"],"tags":["kubernetes","istio"]},{"title":"CentOS 安装 Kubernetes","url":"/2020/05/09/install-kubernetes/","content":"准备安装 Docker上一篇文章 安装 docker\n修改主机名hostnamectl set-hostname k8s-master\n\n修改 &#x2F;etc&#x2F;hosts192.168.140.28 api.k8s.local k8s-master\n\n关闭 swapswapoff -a\n\n注释 /etc/fstab 文件中 swap 分区。\n添加内核参数修改 /etc/sysctl.conf\nfs.file-max = 1000000net.ipv4.ip_forward = 1net.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1\n\n添加 repo 源cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg       https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOF\n\n阿里云公网sed -i &#x27;s|packages.cloud.google.com|mirrors.aliyun.com/kubernetes|&#x27; /etc/yum.repos.d/kubernetes.repo\n\n阿里云内网sed -i &#x27;s|https://packages.cloud.google.com|http://mirrors.cloud.aliyuncs.com/kubernetes|&#x27; /etc/yum.repos.d/kubernetes.repo\n\n安装yum install -y kubeadm kubelet kubectlsystemctl enable kubelet\n\n初始化 master 节点kubeadm init \\    --kubernetes-version=1.18.2 \\    --apiserver-advertise-address=192.168.140.28 \\    --apiserver-bind-port 6443 \\    --pod-network-cidr=10.244.0.0/16 \\    --image-repository registry.aliyuncs.com/google_containers\n\n当出现 Your Kubernetes control-plane has initialized successfully! 即安装成功，并且在下面有相关配置。\nmkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n还有最后一条命令在添加 k8s node 节点时使用到\nkubeadm join 192.168.140.28:6443 --token xxx --discovery-token-ca-cert-hash sha256:xxx\n\n如果忘了保存，可以使用以下命令重新获取到\nkubeadm token create --print-join-command\n\n这时可以使用以下命令查看节点\nkubectl get nodekubectl get pod -A\n\nNAME         STATUS     ROLES    AGE     VERSIONk8s-master   NotReady   master   8m56s   v1.18.2\n\n这边看到状态为 NotReady 是因为未安装网络组件。\n添加 node 节点kubeadm join 192.168.140.28:6443 --token xxx --discovery-token-ca-cert-hash sha256:xxx\n\n安装 Calico 网络wget --unlink -qO calico.yaml https://docs.projectcalico.org/v3.14/manifests/calico.yaml# 10.244.0.0/16 这个地址需要与上面的 kubeadm init --pod-network-cidr 参数值一致sed -i -e &quot;s|192.168.0.0/16|10.244.0.0/16|g&quot; calico.yamlkubectl apply -f calico.yaml\n\n完成这步之后会看到节点的状态变为 Ready。\n安装 Dashboardwget --unlink -qO dashboard.yaml https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yamlkubectl apply -f dashboard.yaml\n\n一般这样是无法通过外网访问，建议在测试环境下修改 kubernetes-dashboard 的 ClusterIP 为 NodePort 将端口暴露出去。\nkubectl edit service kubernetes-dashboard -n kubernetes-dashboard\n\n修改之后，查看 services\nkubernetes-dashboard   kubernetes-dashboard        NodePort    10.106.39.19    &lt;none&gt;        443:31570/TCP            36m\n\n之后访问 https://$&#123;ip&#125;:31570 发现需要 token，下面创建一个管理员用户。\n# admin-user.yamlapiVersion: v1kind: ServiceAccountmetadata:  name: admin-user  namespace: kubernetes-dashboard---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata:  name: admin-userroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: cluster-adminsubjects:  - kind: ServiceAccount    name: admin-user    namespace: kubernetes-dashboard\n\nkubectl apply -f admin-user.yaml\n\n最后查看 token，找到 admin-user 复制 token 即可以管理员身份访问。\nk describe secrets -n kubernetes-dashboard\n\n其他master 参与工作（单机部署）kubectl taint nodes --all node-role.kubernetes.io/master-\n\n命令补全kubectl completion bash &gt; /root/.kube/completion.bash.inc\n\n如果使用 k 作为 kubectl 的别名，需要修改上面生成的文件，在文件末尾修改为\nif [[ $(type -t compopt) = &quot;builtin&quot; ]]; then    complete -o default -F __start_kubectl kubectl    complete -o default -F __start_kubectl kelse    complete -o default -o nospace -F __start_kubectl kubectl    complete -o default -o nospace -F __start_kubectl kfi\n\n最后将下面这段加入 .bash_profile 中，以使用自动补全功能。\n# completesource /usr/share/bash-completion/bash_completionsource /root/.kube/completion.bash.inc# aliasalias k=&#x27;kubectl&#x27;\n","categories":["技术"],"tags":["kubernetes","centos"]},{"title":"Linux 创建虚拟网卡","url":"/2020/05/18/install-virtual-network/","content":"安装相关依赖apt install -y uml-utilities bridge-utils\n\n添加网桥brctl addbr br0\n\n激活网桥ip link set br0 up\n\n添加虚拟网卡ip link set tap0 up\n\n将虚拟网卡添加到指定网桥上brctl addif br0 tap0\n\n给网桥配制ip地址ifconfig br0 172.24.16.10 up\n\n移除brctl delif br0 tap0tunctl -d tap0brctl delbr br0\n\nbrctlUsage: brctl [commands]commands:  addbr          &lt;bridge&gt;                  add bridge  delbr          &lt;bridge&gt;                  delete bridge  addif          &lt;bridge&gt; &lt;device&gt;         add interface to bridge  delif          &lt;bridge&gt; &lt;device&gt;         delete interface from bridge  hairpin        &lt;bridge&gt; &lt;port&gt; &#123;on|off&#125;  turn hairpin on/off  setageing      &lt;bridge&gt; &lt;time&gt;           set ageing time  setbridgeprio  &lt;bridge&gt; &lt;prio&gt;           set bridge priority  setfd          &lt;bridge&gt; &lt;time&gt;           set bridge forward delay  sethello       &lt;bridge&gt; &lt;time&gt;           set hello time  setmaxage      &lt;bridge&gt; &lt;time&gt;           set max message age  setpathcost    &lt;bridge&gt; &lt;port&gt; &lt;cost&gt;    set path cost  setportprio    &lt;bridge&gt; &lt;port&gt; &lt;prio&gt;    set port priority  show           [ &lt;bridge&gt; ]              show a list of bridges  showmacs       &lt;bridge&gt;                  show a list of mac addrs  showstp        &lt;bridge&gt;                  show bridge stp info  stp            &lt;bridge&gt; &#123;on|off&#125;         turn stp on/off\n","categories":["技术"],"tags":["linux"]},{"title":"使用 Docker Compose 安装 Ollama 及模型","url":"/2024/11/13/install-ollama-with-docker-compose/","content":"docker-compose.yamlnetworks:  ollama:    external: trueservices:  ollama:    image: ollama/ollama:0.4.1    container_name: ollama    restart: always    networks:      - ollama    deploy:      resources:        reservations:          # noinspection ComposeUnknownValues          devices:            - driver: nvidia              capabilities: [ gpu ]    environment:      - OLLAMA_KEEP_ALIVE=24h    volumes:      - &quot;$&#123;COMPOSE_DATA_DIR:-/data&#125;/ollama/ollama:/root/.ollama&quot;    ports:      - &quot;11434:11434&quot;  ollama-webui:    image: ghcr.io/open-webui/open-webui:0.3.35    container_name: ollama-webui    restart: always    networks:      - ollama    environment:      - OLLAMA_BASE_URL=http://ollama:11434      - ENV=dev      - WEBUI_AUTH=False      - WHISPER_MODEL_AUTO_UPDATE=False      - RAG_EMBEDDING_MODEL_AUTO_UPDATE=False      - RAG_RERANKING_MODEL_AUTO_UPDATE=False    volumes:      - &quot;$&#123;COMPOSE_DATA_DIR:-/data&#125;/ollama/webui:/app/backend/data&quot;    ports:      - &quot;8080:8080&quot;\n\n拉取模型\nhttps://ollama.com/library\nhttps://ollama.com/library/qwen2.5\n\ndocker exec -it ollama bash\n\nollama listollama pull qwen2.5ollama list\n\n使用模型打开 http://$&#123;IP&#125;:8080 访问 webui，左上角选择模型 qwen2.5：\n\n\n+-----------------------------------------------------------------------------------------+| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     ||-----------------------------------------+------------------------+----------------------+| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC || Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. ||                                         |                        |               MIG M. ||=========================================+========================+======================||   0  Tesla T4                       Off |   00000000:00:10.0 Off |                    0 || N/A   33C    P0             25W /   70W |    5255MiB /  15360MiB |      0%      Default ||                                         |                        |                  N/A |+-----------------------------------------+------------------------+----------------------+|   1  Tesla T4                       Off |   00000000:00:11.0 Off |                    0 || N/A   24C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default ||                                         |                        |                  N/A |+-----------------------------------------+------------------------+----------------------++-----------------------------------------------------------------------------------------+| Processes:                                                                              ||  GPU   GI   CI        PID   Type   Process name                              GPU Memory ||        ID   ID                                                               Usage      ||=========================================================================================||    0   N/A  N/A    326540      C   ...unners/cuda_v12/ollama_llama_server       5252MiB |+-----------------------------------------------------------------------------------------+\n","categories":["技术"],"tags":["docker","ollama","ai","llvm"]},{"title":"简单介绍","url":"/2019/11/20/introduction/","content":"博客使用 Hexo，搭建在 Github Pages，源代码部署在 GitLab 上，使用相关 CI 自动化部署。\n自动化部署_config.ymldeploy:  type: git  repo: https://$&#123;username&#125;:$&#123;token|password&#125;@github.com/starudream/blog.git  branch: master  message: update  name: $&#123;name&#125;  email: $&#123;email&#125;\n\n.gitlab-ci.ymlimage: node:lts-alpinegithub:  stage: publish  script:    - apk add --no-cache git    - git config --global user.name $&#123;name&#125;    - git config --global user.email $&#123;email&#125;    - git clone https://$&#123;name&#125;:$&#123;token|password&#125;@github.com/starudream/blog.git .deploy_git    - npm install &amp;&amp; npm install hexo-cli -g &amp;&amp; hexo clean &amp;&amp; hexo deploy  only:    - masterstages:  - publishcache:  paths:    - node_modules\n"},{"title":"Istio 保留 x-request-id","url":"/2023/03/22/istio-preserve-external-request-id/","content":"apiVersion: networking.istio.io/v1alpha3kind: EnvoyFiltermetadata:  name: api-envoy-filter  namespace: istio-systemspec:  configPatches:    - applyTo: NETWORK_FILTER      match:        context: GATEWAY        listener:          filterChain:            filter:              name: envoy.filters.network.http_connection_manager      patch:        operation: MERGE        value:          typed_config:            &quot;@type&quot;: &quot;type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager&quot;            preserve_external_request_id: true\n","categories":["技术"],"tags":["envoy","istio"]},{"title":"K3S 客户端证书时间延长","url":"/2023/07/21/k3s-client-cert-extend/","content":"k3s 默认的根证书签发 十年，客户端证书签发 一年。\n经常需要重新签发客户端证书，可以通过修改 k3s 的环境变量来延长客户端证书的有效期。\n新增 /etc/default/k3s 文件，并添加以下内容：\nCATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=&quot;3650&quot;\n\n该变量在 k3s server 重新签发证书时有效，或者在安装之前设置。\n","categories":["技术"],"tags":["k3s"]},{"title":"K3S 服务器设置镜像仓库","url":"/2023/07/21/k3s-server-set-registry/","content":"新增 /etc/rancher/k3s/registries.yaml 文件，并添加以下内容：\nmirrors:  &quot;hub.docker.local:5000&quot;:    endpoint:      - &quot;http://hub.docker.local:5000&quot;  &quot;docker.io&quot;:    endpoint:      - &quot;http://hub.docker.local:5000&quot;  &quot;k8s.gcr.io&quot;:    endpoint:      - &quot;http://hub.docker.local:5000&quot;  &quot;quay.io&quot;:    endpoint:      - &quot;http://hub.docker.local:5000&quot;\n\nk3s 的配置支持镜像地址重写，如果拉去镜像 quay.io/prometheus/prometheus:v2.27.1 可以重写到 hub.docker.local:5000/prometheus/prometheus:v2.27.1\n而本地只需要拉去相关镜像然后 docker tag xxx hub.docker.local:5000/xxx 即可。\n","categories":["技术"],"tags":["k3s","mirror"]},{"title":"kubernetes LimitRange 解释","url":"/2024/02/19/k8s-limit-range-explain/","content":"\nmin: 最小值\nmax: 最大值\ndefault 默认 limit 值\ndefaultRequest 默认 request 值\n\n如果 deployment 没有 resources requests 和 limits，那么会使用 defaultRequest 和 default 值，否则使用自定义的值，但是 limits 不能超过 max，requests 不能小于 min。\n","categories":["技术"],"tags":["kubernetes"]},{"title":"免登录只读访问 kubernetes dashboard","url":"/2023/03/22/kubernetes-dashboard-readonly-without-login/","content":"配置基于 v2.7.0 的配置文件，修改了 ClusterRole 和 ClusterRoleBinding，使得 dashboard 只能以只读的方式访问 kubernetes 集群。\n首先需要修改 dashboard 启动 args，移除 --auto-generate-certificates，添加 --enable-insecure-login 和 --enable-skip-login。\n然后修改 Service 端口为 9090，并修改 Deployment 健康检查，根据权限修改 ClusterRole。\n最后通过访问 kubernetes-dashboard.kubernetes-dashboard.svc.cluster.local:9090 即可。\n完整配置注意：以下配置中禁用了对 secret 的访问权限\napiVersion: v1kind: Namespacemetadata:  name: kubernetes-dashboard---apiVersion: v1kind: ServiceAccountmetadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kubernetes-dashboard---apiVersion: v1kind: Servicemetadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kubernetes-dashboardspec:  ports:    - port: 9090      targetPort: 9090  selector:    k8s-app: kubernetes-dashboard---apiVersion: v1kind: Secretmetadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard-certs  namespace: kubernetes-dashboardtype: Opaque---apiVersion: v1kind: Secretmetadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard-csrf  namespace: kubernetes-dashboardtype: Opaquedata:  csrf: &quot;&quot;---apiVersion: v1kind: Secretmetadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard-key-holder  namespace: kubernetes-dashboardtype: Opaque---apiVersion: v1kind: ConfigMapmetadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard-settings  namespace: kubernetes-dashboard---apiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kubernetes-dashboardrules:  - apiGroups: [&quot;&quot;]    resources: [&quot;secrets&quot;]    resourceNames: [&quot;kubernetes-dashboard-key-holder&quot;, &quot;kubernetes-dashboard-certs&quot;, &quot;kubernetes-dashboard-csrf&quot;]    verbs: [&quot;get&quot;, &quot;update&quot;, &quot;delete&quot;]  - apiGroups: [&quot;&quot;]    resources: [&quot;configmaps&quot;]    resourceNames: [&quot;kubernetes-dashboard-settings&quot;]    verbs: [&quot;get&quot;, &quot;update&quot;]  - apiGroups: [&quot;&quot;]    resources: [&quot;services&quot;]    resourceNames: [&quot;heapster&quot;, &quot;dashboard-metrics-scraper&quot;]    verbs: [&quot;proxy&quot;]  - apiGroups: [&quot;&quot;]    resources: [&quot;services/proxy&quot;]    resourceNames: [&quot;heapster&quot;, &quot;http:heapster:&quot;, &quot;https:heapster:&quot;, &quot;dashboard-metrics-scraper&quot;, &quot;http:dashboard-metrics-scraper&quot;]    verbs: [&quot;get&quot;]---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboardrules:  - apiGroups: [&quot;&quot;]    resources: [&quot;configmaps&quot;, &quot;endpoints&quot;, &quot;persistentvolumes&quot;, &quot;persistentvolumeclaims&quot;, &quot;persistentvolumeclaims/status&quot;, &quot;pods&quot;, &quot;replicationcontrollers&quot;, &quot;replicationcontrollers/scale&quot;, &quot;serviceaccounts&quot;, &quot;services&quot;, &quot;services/status&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;&quot;]    resources: [&quot;bindings&quot;, &quot;events&quot;, &quot;limitranges&quot;, &quot;namespaces/status&quot;, &quot;pods/log&quot;, &quot;pods/status&quot;, &quot;replicationcontrollers/status&quot;, &quot;resourcequotas&quot;, &quot;resourcequotas/status&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;&quot;]    resources: [&quot;namespaces&quot;, &quot;nodes&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;apps&quot;]    resources: [&quot;daemonsets&quot;, &quot;daemonsets/status&quot;, &quot;deployments&quot;, &quot;deployments/scale&quot;, &quot;deployments/status&quot;, &quot;replicasets&quot;, &quot;replicasets/scale&quot;, &quot;replicasets/status&quot;, &quot;statefulsets&quot;, &quot;statefulsets/scale&quot;, &quot;statefulsets/status&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;autoscaling&quot;]    resources: [&quot;horizontalpodautoscalers&quot;, &quot;horizontalpodautoscalers/status&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;batch&quot;]    resources: [&quot;cronjobs&quot;, &quot;cronjobs/status&quot;, &quot;jobs&quot;, &quot;jobs/status&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;extensions&quot;]    resources: [&quot;daemonsets&quot;, &quot;daemonsets/status&quot;, &quot;deployments&quot;, &quot;deployments/scale&quot;, &quot;deployments/status&quot;, &quot;ingresses&quot;, &quot;ingresses/status&quot;, &quot;networkpolicies&quot;, &quot;replicasets&quot;, &quot;replicasets/scale&quot;, &quot;replicasets/status&quot;, &quot;replicationcontrollers/scale&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;policy&quot;]    resources: [&quot;poddisruptionbudgets&quot;, &quot;poddisruptionbudgets/status&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;networking.k8s.io&quot;]    resources: [&quot;networkpolicies&quot;, &quot;ingresses&quot;, &quot;ingresses/status&quot;, &quot;ingressclasses&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;storage.k8s.io&quot;]    resources: [&quot;storageclasses&quot;, &quot;volumeattachments&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;metrics.k8s.io&quot;]    resources: [&quot;pods&quot;, &quot;nodes&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;rbac.authorization.k8s.io&quot;]    resources: [&quot;clusterrolebindings&quot;, &quot;clusterroles&quot;, &quot;roles&quot;, &quot;rolebindings&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;apiextensions.k8s.io&quot;]    resources: [&quot;customresourcedefinitions&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]  - apiGroups: [&quot;networking.istio.io&quot;]    resources: [&quot;gateways&quot;, &quot;envoyfilters&quot;, &quot;virtualservices&quot;]    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]---apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kubernetes-dashboardroleRef:  apiGroup: rbac.authorization.k8s.io  kind: Role  name: kubernetes-dashboardsubjects:  - kind: ServiceAccount    name: kubernetes-dashboard    namespace: kubernetes-dashboard---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata:  name: kubernetes-dashboardroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: kubernetes-dashboardsubjects:  - kind: ServiceAccount    name: kubernetes-dashboard    namespace: kubernetes-dashboard---apiVersion: apps/v1kind: Deploymentmetadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kubernetes-dashboardspec:  replicas: 1  revisionHistoryLimit: 10  selector:    matchLabels:      k8s-app: kubernetes-dashboard  template:    metadata:      labels:        k8s-app: kubernetes-dashboard    spec:      securityContext:        seccompProfile:          type: RuntimeDefault      containers:        - name: kubernetes-dashboard          image: kubernetesui/dashboard:v2.7.0          imagePullPolicy: Always          ports:            - containerPort: 9090              protocol: TCP          args:            - --namespace=kubernetes-dashboard            - --enable-insecure-login            - --enable-skip-login          volumeMounts:            - name: kubernetes-dashboard-certs              mountPath: /certs            - mountPath: /tmp              name: tmp-volume          livenessProbe:            httpGet:              scheme: HTTP              path: /              port: 9090            initialDelaySeconds: 30            timeoutSeconds: 30          securityContext:            allowPrivilegeEscalation: false            readOnlyRootFilesystem: true            runAsUser: 1001            runAsGroup: 2001      volumes:        - name: kubernetes-dashboard-certs          secret:            secretName: kubernetes-dashboard-certs        - name: tmp-volume          emptyDir: &#123;&#125;      serviceAccountName: kubernetes-dashboard      nodeSelector:        &quot;kubernetes.io/os&quot;: linux      tolerations:        - key: node-role.kubernetes.io/master          effect: NoSchedule---apiVersion: v1kind: Servicemetadata:  labels:    k8s-app: dashboard-metrics-scraper  name: dashboard-metrics-scraper  namespace: kubernetes-dashboardspec:  ports:    - port: 8000      targetPort: 8000  selector:    k8s-app: dashboard-metrics-scraper---apiVersion: apps/v1kind: Deploymentmetadata:  labels:    k8s-app: dashboard-metrics-scraper  name: dashboard-metrics-scraper  namespace: kubernetes-dashboardspec:  replicas: 1  revisionHistoryLimit: 10  selector:    matchLabels:      k8s-app: dashboard-metrics-scraper  template:    metadata:      labels:        k8s-app: dashboard-metrics-scraper    spec:      securityContext:        seccompProfile:          type: RuntimeDefault      containers:        - name: dashboard-metrics-scraper          image: kubernetesui/metrics-scraper:v1.0.8          ports:            - containerPort: 8000              protocol: TCP          livenessProbe:            httpGet:              scheme: HTTP              path: /              port: 8000            initialDelaySeconds: 30            timeoutSeconds: 30          volumeMounts:          - mountPath: /tmp            name: tmp-volume          securityContext:            allowPrivilegeEscalation: false            readOnlyRootFilesystem: true            runAsUser: 1001            runAsGroup: 2001      serviceAccountName: kubernetes-dashboard      nodeSelector:        &quot;kubernetes.io/os&quot;: linux      tolerations:        - key: node-role.kubernetes.io/master          effect: NoSchedule      volumes:        - name: tmp-volume          emptyDir: &#123;&#125;\n\nRef\nhttps://github.com/kubernetes/dashboard/tree/v2.7.0\nhttps://github.com/kubernetes/dashboard/blob/v2.7.0/docs/common/dashboard-arguments.md\nhttps://gist.github.com/karthik101/201374aee2ebea25ddf6c723858568be\n\n","categories":["技术"],"tags":["kubernetes"]},{"title":"在 Linux 中扩容分区、逻辑卷、文件系统","url":"/2024/11/13/linux-extend-file-systems/","content":"准备工作\nfdisk -l\n\nroot@dev215 [~]# fdisk -lGPT PMBR size mismatch (209715199 != 419430399) will be corrected by write.The backup GPT table is not on the end of the device.Disk /dev/sda: 200 GiB, 214748364800 bytes, 419430400 sectorsDisk model: QEMU HARDDISKUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: gptDisk identifier: 406F0824-6F10-4C6F-8522-FFF0A017AA44Device       Start       End   Sectors Size Type/dev/sda1     2048      4095      2048   1M BIOS boot/dev/sda2     4096   2101247   2097152   1G Linux filesystem/dev/sda3  2101248 209713151 207611904  99G Linux LVMDisk /dev/mapper/opencloudos-root: 66.52 GiB, 71424802816 bytes, 139501568 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/mapper/opencloudos-home: 32.48 GiB, 34871443456 bytes, 68108288 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes\n\nDisklabel type 为 dos 表示为 MBR 分区，为 gpt 表示为 GPT 分区。\n\nlsblk\n\nroot@dev215 [~]# lsblkNAME                 MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTSsda                    8:0    0  200G  0 disk├─sda1                 8:1    0    1M  0 part├─sda2                 8:2    0    1G  0 part /boot└─sda3                 8:3    0   99G  0 part  ├─opencloudos-root 251:0    0 66.5G  0 lvm  /  └─opencloudos-home 251:1    0 32.5G  0 lvm  /home\n\n扩容分区yum install -y cloud-utils-growpart gdisk\n\nMBRLC_ALL=en_US.UTF-8 growpart /dev/vdb 1\n\nGPTLC_ALL=en_US.UTF-8 growpart /dev/sda 3\n\n出现以 CHANGED 开头的信息表示扩容成功。\nroot@dev215 [/data]# growpart /dev/sda 3CHANGED: partition=3 start=2101248 old: size=207611904 end=209713151 new: size=417329119 end=419430366root@dev215 [/data]# lsblkNAME                 MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTSsda                    8:0    0  200G  0 disk├─sda1                 8:1    0    1M  0 part├─sda2                 8:2    0    1G  0 part /boot└─sda3                 8:3    0  199G  0 part  ├─opencloudos-root 251:0    0 66.5G  0 lvm  /  └─opencloudos-home 251:1    0 32.5G  0 lvm  /home\n\n扩容逻辑卷在上面的 lsblk 信息中，实际上根目录 / 和 /home 的类型都是 lvm。\npvresize /dev/sda3lvextend -L +100G /dev/opencloudos/rootxfs_growfs /\n\nroot@dev215 [/data]# pvs  PV         VG          Fmt  Attr PSize    PFree  /dev/sda3  opencloudos lvm2 a--  &lt;199.00g 100.00g  root@dev215 [/data]# pvresize /dev/sda3  Physical volume &quot;/dev/sda3&quot; changed  1 physical volume(s) resized or updated / 0 physical volume(s) not resized  root@dev215 [/data]# lvdisplay  --- Logical volume ---  LV Path                /dev/opencloudos/home  LV Name                home  VG Name                opencloudos  LV UUID                Mrv5DQ-JeQx-mKdM-Vn9u-qOtw-Yl9k-TbkTjH  LV Write Access        read/write  LV Creation host, time dev215, 2024-11-01 10:35:13 +0800  LV Status              available  # open                 1  LV Size                &lt;32.48 GiB  Current LE             8314  Segments               1  Allocation             inherit  Read ahead sectors     auto  - currently set to     256  Block device           251:1  --- Logical volume ---  LV Path                /dev/opencloudos/root  LV Name                root  VG Name                opencloudos  LV UUID                pmaZSg-3JnI-yXfm-8N5Z-arW7-mstK-P0Atir  LV Write Access        read/write  LV Creation host, time dev215, 2024-11-01 10:35:14 +0800  LV Status              available  # open                 1  LV Size                &lt;66.52 GiB  Current LE             17029  Segments               1  Allocation             inherit  Read ahead sectors     auto  - currently set to     256  Block device           251:0root@dev215 [/data]# lvextend -L +100G /dev/opencloudos/root  Size of logical volume opencloudos/root changed from &lt;66.52 GiB (17029 extents) to &lt;166.52 GiB (42629 extents).  Logical volume opencloudos/root successfully resized.root@dev215 [/data]# lvdisplay  --- Logical volume ---  LV Path                /dev/opencloudos/home  LV Name                home  VG Name                opencloudos  LV UUID                Mrv5DQ-JeQx-mKdM-Vn9u-qOtw-Yl9k-TbkTjH  LV Write Access        read/write  LV Creation host, time dev215, 2024-11-01 10:35:13 +0800  LV Status              available  # open                 1  LV Size                &lt;32.48 GiB  Current LE             8314  Segments               1  Allocation             inherit  Read ahead sectors     auto  - currently set to     256  Block device           251:1  --- Logical volume ---  LV Path                /dev/opencloudos/root  LV Name                root  VG Name                opencloudos  LV UUID                pmaZSg-3JnI-yXfm-8N5Z-arW7-mstK-P0Atir  LV Write Access        read/write  LV Creation host, time dev215, 2024-11-01 10:35:14 +0800  LV Status              available  # open                 1  LV Size                &lt;166.52 GiB  Current LE             42629  Segments               1  Allocation             inherit  Read ahead sectors     auto  - currently set to     256  Block device           251:0root@dev215 [/data]# pvs  PV         VG          Fmt  Attr PSize    PFree  /dev/sda3  opencloudos lvm2 a--  &lt;199.00g    0\n\n扩容文件系统ext*resize2fs /dev/vdb1\n\nxfsyum install -y xfsprogsxfs_growfs /mnt\n\nRef\nhttps://web.archive.org/web/20241113015538/https://help.aliyun.com/zh/ecs/user-guide/extend-the-partitions-and-file-systems-of-disks-on-a-linux-instance\nhttps://web.archive.org/web/20241113015851/https://help.aliyun.com/zh/ecs/use-cases/extend-an-lv-by-using-lvm\n\n","categories":["技术"],"tags":["linux","ops"]},{"title":"在 SpringBoot 应用中使用 Logback 将日志发送到 ELK","url":"/2024/06/27/logback-redis-elk/","content":"RedisAppenderimport ch.qos.logback.classic.spi.ILoggingEvent;import ch.qos.logback.classic.spi.IThrowableProxy;import ch.qos.logback.classic.spi.ThrowableProxyUtil;import ch.qos.logback.core.UnsynchronizedAppenderBase;import cn.hutool.core.util.StrUtil;import cn.hutool.json.JSONUtil;import io.lettuce.core.RedisClient;import io.lettuce.core.RedisURI;import io.lettuce.core.api.async.RedisAsyncCommands;import lombok.Getter;import lombok.Setter;import java.time.Duration;import java.util.Date;@Getter@Setterpublic class RedisAppender extends UnsynchronizedAppenderBase&lt;ILoggingEvent&gt; &#123;    private String host;    private Integer port;    private String password;    private String key;    private RedisClient redisClient;    private RedisAsyncCommands&lt;String, String&gt; async;    @Override    protected void append(ILoggingEvent event) &#123;        if (redisClient == null) &#123;            return;        &#125;        LoggerEntity entity = new LoggerEntity();        entity.setTimestamp(new Date(event.getTimeStamp()));        entity.setLevel(event.getLevel().toString());        entity.setCaller(event.getLoggerName());        entity.setThread(event.getThreadName());        entity.setMessage(event.getFormattedMessage());        IThrowableProxy throwableProxy = event.getThrowableProxy();        if (throwableProxy != null) &#123;            entity.setThrowable(ThrowableProxyUtil.asString(throwableProxy));        &#125;        async.rpush(key, JSONUtil.toJsonStr(entity));    &#125;    @Override    public void start() &#123;        super.start();        initRedis();    &#125;    private void initRedis() &#123;        if (StrUtil.isEmpty(host) || StrUtil.isEmpty(key)) &#123;            return;        &#125;        try &#123;            RedisURI uri = RedisURI                .builder()                .withHost(host)                .withPort(port)                .withPassword(password.toCharArray())                .withTimeout(Duration.ofSeconds(10))                .build();            redisClient = RedisClient.create(uri);            async = redisClient.connect().async();        &#125; catch (Exception e) &#123;            System.out.printf(&quot;Initialize Logger Redis Exception: %s\\n&quot;, e.getMessage());        &#125;    &#125;    @Override    public void stop() &#123;        closeRedis();        super.stop();    &#125;    private void closeRedis() &#123;        if (redisClient != null) &#123;            redisClient.close();        &#125;    &#125;&#125;\n\nlogback-spring.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration&gt;    &lt;include resource=&quot;org/springframework/boot/logging/logback/base.xml&quot;/&gt;    &lt;appender name=&quot;REDIS&quot; class=&quot;xxx.RedisAppender&quot;&gt;        &lt;host&gt;$&#123;LOGGER_REDIS_HOST:-&#125;&lt;/host&gt;        &lt;port&gt;$&#123;LOGGER_REDIS_PORT:-6379&#125;&lt;/port&gt;        &lt;password&gt;$&#123;LOGGER_REDIS_PASSWORD:-&#125;&lt;/password&gt;        &lt;key&gt;$&#123;LOGGER_REDIS_KEY:-log:test&#125;&lt;/key&gt;    &lt;/appender&gt;    &lt;root level=&quot;info&quot;&gt;        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;        &lt;!-- &lt;appender-ref ref=&quot;FILE&quot;/&gt; --&gt;        &lt;appender-ref ref=&quot;REDIS&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;\n\nlogstashinput &#123;    redis &#123;        id =&gt; &quot;test&quot;        host =&gt; &quot;xxxx&quot;        port =&gt; &quot;xxxx&quot;        password =&gt; &quot;p1ssw0rd&quot;        data_type =&gt; &quot;list&quot;        threads =&gt; 4        key =&gt; &quot;log:test&quot;        type =&gt; &quot;test&quot;    &#125;&#125;filter &#123;    date &#123;        match =&gt; [&quot;ts&quot;, &quot;UNIX&quot;, &quot;UNIX_MS&quot;, &quot;ISO8601&quot;]        timezone =&gt; &quot;Asia/Shanghai&quot;        target =&gt; &quot;@timestamp&quot;        remove_field =&gt; [&quot;ts&quot;]    &#125;    ruby &#123;        code =&gt; &#x27;          if event.get(&quot;msg&quot;) and event.get(&quot;msg&quot;).length &gt; 512*1024            event.set(&quot;msg&quot;, &quot;IGNORED LARGE MSG&quot;)          end        &#x27;    &#125;&#125;output &#123;    elasticsearch &#123;        id =&gt; &quot;log&quot;        hosts =&gt; &quot;es-master:9200&quot;        user =&gt; &quot;logstash_internal&quot;        password =&gt; &quot;$&#123;LOGSTASH_INTERNAL_PASSWORD&#125;&quot;        index =&gt; &quot;logstash-%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;&quot;    &#125;&#125;\n","categories":["技术"],"tags":["elasticsearch","kibana","java","logback","logstash","redis"]},{"title":"Linux 安装 NVIDIA 驱动和容器工具包","url":"/2024/11/13/linux-install-nvidia-driver-and-container-toolkit/","content":"查看 GPU 信息lspci | grep -i nvidia\n\n驱动yum install -y kernel-devel gcc\n\nTestnvidia-smi\n\n容器工具包\nInstall Guide\nUSTC Mirrors\n\nInstallcurl -s -L https://mirrors.ustc.edu.cn/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo | \\  sed &#x27;s#nvidia.github.io#mirrors.ustc.edu.cn#g&#x27; | tee /etc/yum.repos.d/nvidia-container-toolkit.repo\n\nyum install -y nvidia-container-toolkit\n\nConfigurenvidia-ctk runtime configure --runtime=docker\n\nequivalent to edit /etc/docker/daemon.json add following content:\n&#123;  &quot;runtimes&quot;: &#123;    &quot;nvidia&quot;: &#123;      &quot;args&quot;: [],      &quot;path&quot;: &quot;nvidia-container-runtime&quot;    &#125;  &#125;&#125;\n\nthen restart docker daemon\nsystemctl restart docker\n\nTestdocker run --rm --runtime=nvidia --gpus all ubuntu:24.04 nvidia-smi\n\n+-----------------------------------------------------------------------------------------+| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     ||-----------------------------------------+------------------------+----------------------+| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC || Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. ||                                         |                        |               MIG M. ||=========================================+========================+======================||   0  Tesla T4                       Off |   00000000:00:10.0 Off |                    0 || N/A   24C    P8              8W /   70W |       3MiB /  15360MiB |      0%      Default ||                                         |                        |                  N/A |+-----------------------------------------+------------------------+----------------------+|   1  Tesla T4                       Off |   00000000:00:11.0 Off |                    0 || N/A   25C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default ||                                         |                        |                  N/A |+-----------------------------------------+------------------------+----------------------++-----------------------------------------------------------------------------------------+| Processes:                                                                              ||  GPU   GI   CI        PID   Type   Process name                              GPU Memory ||        ID   ID                                                               Usage      ||=========================================================================================||  No running processes found                                                             |+-----------------------------------------------------------------------------------------+\n","categories":["技术"],"tags":["linux","gpu","nvidia","container"]},{"title":"使用 glibMacOS 制作 MacOS 安装镜像","url":"/2021/11/01/mac-install-image-with-glibmacos/","content":"下载\n首先从 GitHub 上下载最新的代码。\n\n解压后，运行 gibMacOS.bat。\n\n选择 MacOS 版本，输入序号并按回车。\n\n等待下载完成。\n\n\n刻录\n插入 U 盘。\n\n运行 MakeInstall.bat。\n\n选择正确的磁盘，并输入前面的序号，按下回车，再输入 Y 按下回车（U 盘内所有数据将会被清除）。\n\n进入 gibMacOS\\macOS Downloads\\publicrelease 目录，按着 shift 并右击相应版本的文件夹，选择 复制文件地址。\n\n回到 MakeInstall.bat 窗口，右击粘贴刚才复制的路径并按回车。\n\n等待直到制作完成。\n\n\n其他该工具下载可能较慢，建议在初始化的冒出的 xml 连接中直接找对应的文件。\n","categories":["技术"],"tags":["mac"]},{"title":"Mac 源码安装 node 时 `No Xcode or CLT version detected!` 错误","url":"/2021/06/18/mac-node-no-xcode-detected/","content":"解决办法重新安装 Xcode Tools\nsudo rm -rf $(xcode-select -p)sudo xcode-select --install\n","categories":["技术"],"tags":["mac","node","xcode"]},{"title":"配置 Maven 镜像","url":"/2024/06/26/maven-mirror/","content":"~/.m2/settings.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;settings    xmlns=&quot;http://maven.apache.org/SETTINGS/1.2.0&quot;    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;    xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.2.0 https://maven.apache.org/xsd/settings-1.2.0.xsd&quot;&gt;    &lt;mirrors&gt;        &lt;mirror&gt;            &lt;id&gt;aliyun&lt;/id&gt;            &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;            &lt;name&gt;aliyun&lt;/name&gt;            &lt;url&gt;https://maven.aliyun.com/repository/public/&lt;/url&gt;        &lt;/mirror&gt;    &lt;/mirrors&gt;&lt;/settings&gt;\n","categories":["技术"],"tags":["java","maven"]},{"title":"米游社 2.62.2 版本 salt 获取","url":"/2023/11/09/miyoushe-salt-2.62.2/","content":"首先从 miyoushe 官网下载 apk，然后使用 jadx 反编译 apk。\n从 文章 中可知生成 DS 算法的位置位于 com.mihoyo.hyperion.net 包内，\n使用 jadx 打开到对应目录，可以找到 bbbbb.a2222、 aaaaa.a2222、 aaaaa.b5555，分别为 DS1 DS2 的算法实现。\n\n\n右键方法名，选择 Find Usage，可以看到对应的实现。\n\n\n\n\n可以看到 DS LK2 K2 相关的加密算法，通过相关函数输入到 bbbbb.a2222 方法中，找到函数的参数，即为 salt。\n\n\n下面以 DS 为例，把传入 bbbbb.a2222 方法的方法与参数拷贝出来，稍加修改，得到下面的代码：\nimport java.util.ArrayList;import java.util.Collection;public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(f1(f276382k));    &#125;    public static final int[] f276382k = &#123;192, -74, 180, 222, 90, 198, -177147, -84, -66, 126, 168, 156, 186, 66, -88, -4782969, 126, 216, -98, -118, -88, -4782969, -86, 180, 216, 102, 156, 126, -100, -59049, -177147, 198&#125;;    public static String f1(int[] iArr) &#123;        int i11;        StringBuilder sb2 = new StringBuilder();        ArrayList&lt;Number&gt; arrayList = new ArrayList(iArr.length);        for (int i12 : iArr) &#123;            if (i12 &lt; 0) &#123;                i11 = ((double) (-i12)) &gt;= Math.pow(3.0d, 6.0d) ? (int) (((Math.log(-i12) / Math.log(3.0d)) - 6) + 48) : ~i12;            &#125; else &#123;                i11 = (i12 / 3) + 48;            &#125;            arrayList.add(Integer.valueOf(i11));        &#125;        ArrayList arrayList2 = new ArrayList(Z(arrayList, 10));        for (Number number : arrayList) &#123;            sb2.append((char) number.intValue());            arrayList2.add(sb2);        &#125;        String sb3 = sb2.toString();        return sb3;    &#125;    public static final &lt;T&gt; int Z(Iterable&lt;? extends T&gt; iterable, int i11) &#123;        return iterable instanceof Collection ? ((Collection) iterable).size() : i11;    &#125;&#125;\n\n运行后得到 pIlzNr5SAZhdnFW8ZxauW8UlxRdZc45r 即为 salt，带入到相关 api 验证一下，成功。\nRef\nhttps://github.com/skylot/jadx\nhttps://github.com/UIGF-org/mihoyo-api-collect/issues/1\nhttps://github.com/Azure99/GenshinPlayerQuery/issues/20\n\n","categories":["技术"],"tags":["android","game","mihoyo"]},{"title":"修改主题 Pisces","url":"/2019/12/19/motify-theme-pisces/","content":"--- a/themes/next/layout/_scripts/pjax.swig+++ b/themes/next/layout/_scripts/pjax.swig@@ -15,8 +15,8 @@ var pjax = new Pjax(&#123;   scrollTo : !CONFIG.bookmark.enable &#125;);-window.addEventListener(&#x27;pjax:success&#x27;, () =&gt; &#123;-  document.querySelectorAll(&#x27;script[pjax], script#page-configurations, #pjax script&#x27;).forEach(element =&gt; &#123;+window.addEventListener(&#x27;pjax:success&#x27;, function() &#123;+  document.querySelectorAll(&#x27;script[pjax], script#page-configurations, #pjax script&#x27;).forEach(function(element) &#123;     var code = element.text || element.textContent || element.innerHTML || &#x27;&#x27;;     var parent = element.parentNode;     parent.removeChild(element);--- a/themes/next/layout/_third-party/comments/disqus.swig+++ b/themes/next/layout/_third-party/comments/disqus.swig@@ -41,7 +41,7 @@         // load directly when there&#x27;s no a scrollbar         window.addEventListener(&#x27;load&#x27;, loadComments, false);       &#125; else &#123;-        var disqus_scroll = () =&gt; &#123;+        var disqus_scroll = function() &#123;           // offsetTop may changes because of manually resizing browser window or lazy loading images.           var offsetTop = document.getElementById(&#x27;comments&#x27;).offsetTop - window.innerHeight;           var scrollTop = window.scrollY;--- a/themes/next/layout/_third-party/quicklink.swig+++ b/themes/next/layout/_third-party/quicklink.swig@@ -3,12 +3,12 @@   &lt;script src=&quot;&#123;&#123; quicklink_uri &#125;&#125;&quot;&gt;&lt;/script&gt;   &lt;script&gt;     &#123;%- if page.quicklink.delay %&#125;-      window.addEventListener(&#x27;load&#x27;, () =&gt; &#123;+      window.addEventListener(&#x27;load&#x27;, function() &#123;     &#123;%- endif %&#125;       quicklink(&#123;         timeout: &#123;&#123; page.quicklink.timeout &#125;&#125;,         priority: &#123;&#123; page.quicklink.priority &#125;&#125;,-        ignores: [uri =&gt; uri.includes(&#x27;#&#x27;),uri =&gt; uri == &#x27;&#123;&#123; url | replace(&#x27;index.html&#x27;, &#x27;&#x27;) &#125;&#125;&#x27;,&#123;&#123; page.quicklink.ignores &#125;&#125;]+        ignores: [function(uri) &#123; return uri.includes(&#x27;#&#x27;) &#125;, function(uri) &#123; return uri === &#x27;&#123;&#123; url | replace(&#x27;index.html&#x27;, &#x27;&#x27;) &#125;&#125;&#x27; &#125;, &#123;&#123; page.quicklink.ignores &#125;&#125;]       &#125;);     &#123;%- if page.quicklink.delay %&#125;       &#125;);\n","categories":["主题"],"tags":["theme","pisces"]},{"title":"在 MyBatisPlus 中使用 Wrapper 更新时自动填充字段失效","url":"/2024/06/27/mybatis-plus-autometa-when-wrapper/","content":"因为 mp 只能在传入 Entity 的情况下自动填充字段。\nMybatisMetaAspectimport cn.hutool.core.util.ReflectUtil;import com.baomidou.mybatisplus.core.conditions.AbstractWrapper;import lombok.RequiredArgsConstructor;import lombok.extern.slf4j.Slf4j;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ConcurrentMap;@Slf4j@Aspect@Component@RequiredArgsConstructorpublic class MybatisMetaAspect &#123;    private final ConcurrentMap&lt;Class&lt;?&gt;, Object&gt; entityMap = new ConcurrentHashMap&lt;&gt;();    @Pointcut(&quot;execution(* com.baomidou.mybatisplus.core.mapper.BaseMapper.update(com.baomidou.mybatisplus.core.conditions.Wrapper))&quot;)    public void update() &#123;    &#125;    @Around(&quot;update()&quot;)    public Object aroundUpdate(ProceedingJoinPoint pjp) &#123;        try &#123;            Object result = invoke(pjp);            if (result != null) &#123;                return result;            &#125;            return pjp.proceed(pjp.getArgs());        &#125; catch (Throwable e) &#123;            log.error(&quot;mybatis around update error&quot;, e);        &#125;        return null;    &#125;    private Object invoke(ProceedingJoinPoint pjp) &#123;        Object[] args = pjp.getArgs();        if (args == null || args.length != 1) &#123;            return null;        &#125;        Object arg = args[0];        if (arg instanceof AbstractWrapper&lt;?, ?, ?&gt; wrapper) &#123;            Class&lt;?&gt; entityClass = wrapper.getEntityClass();            if (entityClass == null) &#123;                log.warn(&quot;Detected that the entity is empty, which will cause automatic filling to fail. Please use `new UpdateWrapper&lt;&gt;(new T())` or `new UpdateWrapper&lt;&gt;(T.class)` instead.&quot;);                return null;            &#125;            Object entity = entityMap.get(entityClass);            if (entity == null) &#123;                entity = ReflectUtil.newInstance(entityClass);                entityMap.put(entityClass, entity);            &#125;            return ReflectUtil.invoke(pjp.getThis(), &quot;update&quot;, entity, arg);        &#125;        return null;    &#125;&#125;\n","categories":["技术"],"tags":["java","mybatis-plus"]},{"title":"在 nexus3 中使用 nginx 配置代理可以访问 docker proxy 并推送至 docker hosted","url":"/2024/11/28/nexus3-docker-proxy-and-group/","content":"\n\ndocker pull 通过 docker-group 既可以拉取 docker-hosted 镜像又可以拉取 docker-proxy 的镜像。\n由于 nexus3 的限制，如果只代理至 docker-group 的话，无法推送镜像，所以需要将推送代理至 docker-hosted。\n默认的 GET 与 HEAD 请求代理至 docker-group，其余的 PUT POST 请求代理至 docker-group。\nhttp &#123;    map $request_method $repo_name &#123;        default hosted;        GET group;        HEAD group;    &#125;    server &#123;        location /v2/ &#123;            client_max_body_size 8000M;            rewrite /v2/(.*) /repository/docker-$repo_name/v2/$1 break;            proxy_pass http://$&#123;IP&#125;:8081;            proxy_set_header Host $host;            proxy_set_header X-Real-IP $remote_addr;            proxy_set_header X-Real-PORT $remote_port;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Forwarded-Proto $scheme;        &#125;    &#125;&#125;\n","categories":["技术"],"tags":["docker","nginx","nexus3"]},{"title":"Nginx location 的一些例子","url":"/2022/08/04/nginx-location-proxy-example/","content":"proxy_pass在 nginx 中配置 proxy_pass 代理转发时，如果在 proxy_pass 后面的 url 加 /，表示绝对根路径；如果没有 /，表示相对路径。\n假设下面四种情况分别用 http://192.168.1.1/proxy/test.html 进行访问。\n第一种location /proxy/ &#123;    proxy_pass http://127.0.0.1/;&#125;\n\n\nhttp://127.0.0.1/test.html\n\n第二种location /proxy/ &#123;    proxy_pass http://127.0.0.1;&#125;\n\n\nhttp://127.0.0.1/proxy/test.html\n\n第三种location /proxy/ &#123;    proxy_pass http://127.0.0.1/aaa/;&#125;\n\n\nhttp://127.0.0.1/aaa/test.html\n\n第四种location /proxy/ &#123;    proxy_pass http://127.0.0.1/aaa;&#125;\n\n\nhttp://127.0.0.1/aaatest.html\n\n","categories":["技术"],"tags":["nginx"]},{"title":"Nginx 在同一个路径下反代 HTTP 和 WebSocket","url":"/2022/08/04/nginx-proxy-http-and-websocket/","content":"server &#123;  // settings  location /api/ &#123;    try_files /nonexistent @$http_upgrade;  &#125;  location @ &#123;    rewrite ^/api/(.*) /$1 break;    proxy_pass http://127.0.0.1:4080;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header X-Real-PORT $remote_port;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  &#125;  location @websocket &#123;    rewrite ^/api/(.*) /$1 break;    proxy_pass http://127.0.0.1:4080;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header X-Real-PORT $remote_port;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    # websocket    proxy_http_version 1.1;    proxy_set_header Connection &quot;Upgrade&quot;;    proxy_set_header Upgrade $http_upgrade;  &#125;&#125;\n","categories":["技术"],"tags":["nginx"]},{"title":"MacOS 发送通知","url":"/2023/05/16/notify-on-macos/","content":"osascript -l AppleScript -e &#x27;display notification &quot;Hello World!&quot; with title &quot;Hi!&quot;&#x27;\n","categories":["技术"],"tags":["macos"]},{"title":"通过 pid 查看 k8s pod name","url":"/2024/02/19/pid-for-k8s-pod/","content":"nsenter -t $PID -u hostname\n","categories":["技术"],"tags":["kubernetes"]},{"title":"PVE 修改 hostname","url":"/2023/07/21/pve-change-hostname/","content":"安装 官方教程 可以在没有虚拟机的 PVE 上修改 hostname。\n具体操作是依次修改下面的文件，将其中的 old-hostname 替换为 new-hostname：\nnano /etc/hostsnano /etc/hostnamenano /etc/pve/corosync.confnano /etc/mailnamenano /etc/postfix/main.cf\n\n同时将 /var/lib/rrdcached/db/pve2-&#123;node,storage&#125;/old-hostname 的内容复制到 /var/lib/rrdcached/db/pve2-&#123;node,storage&#125;/new-hostname 并删除旧目录。\n\n以下操作非常危险，很可能造成数据损坏，正确的做法应该是将虚拟机备份恢复到其他机器上\n\n如果机器上有虚拟机则需要做以下额外的操作才可以在 WebUI 中看到正确的节点。\n进入 /etc/pve/nodes 目录，将 old-hostname 下的文件夹内的内容移动到 new-hostname 相应的文件夹下\n重启后尝试启动虚拟机，如果出现错误 TASK ERROR: activating LV &#39;pve/vm-xxx&#39; failed:   Activation of logical volume pve/vm-xxx is prohibited while logical volume pve/data_tmeta is active. 尝试使用以下命令：\nlvchange -an pve/data_tdatalvchange -an pve/data_tmetalvchange -ay\n","categories":["技术"],"tags":["pve"]},{"title":"PVE 启动 IOMMU","url":"/2023/07/21/pve-enable-iommu/","content":"INTEL\n修改 /etc/default/grub\n\n\n添加 intel_iommu=on\n\n修改 GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet intel_iommu=on&quot;\n\n\n\n加载 vifo 系统模块\n\nvim /etc/modules\n\n添加以下内容\nvfiovfio_iommu_type1vfio_pcivfio_virqfd\n\n\n更新 grub 并重启\n\nupdate-grubreboot\n\n\n重启后运行以下命令，如果有输出基本可确认成功\n\ndmesg | grep -e DMAR -e IOMMU\n\nAMD步骤与 INTEL 类似，把 intel 相关修改为 amd\n","categories":["技术"],"tags":["pve","iommu"]},{"title":"PVE 移除 No valid subscription 提示","url":"/2023/07/21/pve-hidden-no-valid-subscription/","content":"cd /usr/share/javascript/proxmox-widget-toolkitcp proxmoxlib.js proxmoxlib.js.bakvim proxmoxlib.js\n\n将 No valid subscription 前面的 Ext.Msg.show 替换为 void\nsystemctl reload pveproxy.service\n","categories":["技术"],"tags":["pve"]},{"title":"PVE 在存在虚拟机的情况下添加到集群","url":"/2023/07/21/pve-join-cluster-if-exists-vms/","content":"此操作危险，不建议使用\nmkdir -p ~/cluster_bakmv /etc/pve/nodes/&#123;hostname&#125;/qemu-server/* ~/cluster_bak\n\n然后在 WebUI 中操作添加到集群，添加完成后将备份的文件复制回来：\nmv ~/cluster_bak/* /etc/pve/nodes/&#123;hostname&#125;/qemu-server/\n","categories":["技术"],"tags":["pve"]},{"title":"kubectl 重启某个 Namespace 下的所有 Deployment","url":"/2024/02/19/restart-all-deployment-in-namespace/","content":"NAMESPACE=&quot;arc-os&quot;for DEPLOY in $(kubectl get deployments -n $NAMESPACE | tail -n +2 | cut -d &#x27; &#x27; -f 1); do kubectl rollout restart deployments/$DEPLOY -n $NAMESPACE; done\n","categories":["技术"],"tags":["kubernetes","kubectl"]},{"title":"Samba 文件共享","url":"/2019/11/28/samba/","content":"安装apt install samba\n\n配置新建系统用户useradd -M -s /sbin/nologin $&#123;user&#125;\n\n新建 samba 用户smbpasswd -a $&#123;user&#125;\n\n修改 samba 配置文件在文件末尾添加如下配置：\n[Samba]  comment = Samba  path = /opt/samba  guest ok = no  read only = no  browseable = yes\n\n不要忘了授予 $&#123;user&#125; /opt/samba 目录权限\n重启 samba 服务systemctl restart smbd.service\n","categories":["技术"],"tags":["samba"]},{"title":"脚本将镜像文件推送到 Docker Registry","url":"/2024/11/13/shell-push-archive-files-to-docker-registry/","content":"Import#!/usr/bin/env bashset -eREGISTRY=&quot;hub.starudream.local&quot;function load() &#123;  if [ ! -f &quot;$1&quot; ]; then    echo &quot;file not found: $1&quot;    exit 1  fi  res=$(docker image load -i &quot;$1&quot; 2&gt;/dev/null | grep &quot;Loaded image:&quot; || true)  images=$&#123;res//Loaded image: /&#125;  for image in $images; do    echo &quot;-&gt; loaded $image&quot;    if [ -z $REGISTRY ]; then      continue    fi    cnt=$(echo &quot;$image&quot; | awk -F/ &quot;&#123;print NF-1&#125;&quot;)    name=$image    case $cnt in    0)      name=&quot;library/$image&quot;      ;;    1) ;;    *)      part=$&#123;image%/*&#125;      left=$&#123;part%/*&#125;      name=$&#123;image/$left\\//&#125;      ;;    esac    docker image tag &quot;$image&quot; &quot;$REGISTRY/$name&quot;    docker image push &quot;$REGISTRY/$name&quot;    echo &quot;=&gt; pushed $image to $REGISTRY/$name&quot;    docker image rm &quot;$REGISTRY/$name&quot;    docker image rm &quot;$image&quot; || true  done&#125;cnt=$(grep -c $REGISTRY /etc/hosts || true)if [ &quot;$cnt&quot; -eq 0 ]; then  REGISTRY=&quot;&quot;elif [ &quot;$PUSH_REGISTRY&quot; = 0 ]; then  REGISTRY=&quot;&quot;fiif [ -z &quot;$1&quot; ]; then  files=$(find . -type f -name &quot;*.tar.gz&quot; | sort -u)  for file in $files; do    echo &quot;&gt;&gt; found $file&quot;    load &quot;$file&quot;  doneelse  load &quot;$1&quot;fi\n\nExport#!/usr/bin/env bashset -eCUR_DIR=$(cd &quot;$(dirname &quot;$&#123;BASH_SOURCE[0]&#125;&quot;)&quot; &amp;&amp; pwd)ROOT_DIR=$(dirname &quot;$CUR_DIR&quot;)mkdir -p &quot;$ROOT_DIR&quot;/imagesfunction save() &#123;  if [ ! -f &quot;$1&quot; ]; then    echo &quot;file not found: $1&quot;    exit 1  fi  images=$(docker-compose -f &quot;$1&quot; config --images | sort -u)  for image in $images; do    name=$&#123;image////-&#125;    name=$&#123;name//:/_&#125;    if [ -f &quot;$ROOT_DIR/images/$name.tar.gz&quot; ]; then      echo &quot;-&gt; exist $name.tar.gz, skip&quot;      continue    fi    docker image pull --platform linux/amd64 &quot;$image&quot;    echo &quot;=&gt; save $image to $name.tar.gz&quot;    docker image save &quot;$image&quot; | gzip &gt; &quot;$ROOT_DIR/images/$name.tar.gz&quot;  done&#125;if [ -z &quot;$1&quot; ]; then  files=$(find . -type f -name &quot;docker-compose*.yaml&quot; | sort -u)  for file in $files; do    echo &quot;&gt;&gt; found $file&quot;    save &quot;$file&quot;  doneelse  save &quot;$1&quot;fi\n","categories":["技术"],"tags":["docker","registry"]},{"title":"查询 timescale table 行数","url":"/2024/02/19/select-timescale-table/","content":"SELECT h.schema_name,       h.table_name,       h.id AS table_id,       h.associated_table_prefix,       row_estimate.row_estimateFROM _timescaledb_catalog.hypertable h         CROSS JOIN LATERAL (    SELECT SUM(cl.reltuples) AS row_estimate    FROM _timescaledb_catalog.chunk c             JOIN pg_class cl ON cl.relname = c.table_name    WHERE c.hypertable_id = h.id    GROUP BY h.schema_name, h.table_name    ) row_estimateORDER BY schema_name, row_estimate DESC, table_name;\n","categories":["技术"],"tags":["timescaledb"]},{"title":"在 Chrome 地址栏中显示完整网址","url":"/2020/06/28/show-full-path-in-chrome/","content":"打开 chrome://flags/#omnibox-context-menu-show-full-urls 地址，将 Context menu show full URLs 设置为 Enabled。\n重启 Chrome 后，在地址栏右击勾选 总是显示完整网址。\n","categories":["技术"],"tags":["chrome"]},{"title":"优化 Springdoc Swagger 枚举显示","url":"/2024/06/27/springdoc-swagger-enum/","content":"搭配 MybatisPlus 的 IEnum 类型，优化枚举显示\n修改前\n\n修改后\n\nEnumConverterimport cn.hutool.core.convert.Convert;import cn.hutool.core.util.ReflectUtil;import com.baomidou.mybatisplus.annotation.IEnum;import com.fasterxml.jackson.databind.JavaType;import com.fasterxml.jackson.databind.ObjectMapper;import io.swagger.v3.core.converter.AnnotatedType;import io.swagger.v3.core.converter.ModelConverter;import io.swagger.v3.core.converter.ModelConverterContext;import io.swagger.v3.oas.models.media.Schema;import lombok.RequiredArgsConstructor;import org.springdoc.core.providers.ObjectMapperProvider;import org.springframework.stereotype.Component;import java.util.Iterator;@Component@RequiredArgsConstructorpublic class EnumConverter implements ModelConverter &#123;    private final ObjectMapperProvider objectMapperProvider;    @SuppressWarnings(&#123;&quot;unchecked&quot;, &quot;rawtypes&quot;&#125;)    @Override    public Schema&lt;?&gt; resolve(AnnotatedType type, ModelConverterContext context, Iterator&lt;ModelConverter&gt; chain) &#123;        Schema&lt;?&gt; nextSchema = chain.hasNext() ? chain.next().resolve(type, context, chain) : null;        ObjectMapper objectMapper = objectMapperProvider.jsonMapper();        JavaType javaType = objectMapper.constructType(type.getType());        if (javaType != null &amp;&amp; javaType.isEnumType()) &#123;            Class&lt;Enum&gt; enumClass = (Class&lt;Enum&gt;) javaType.getRawClass();            Enum[] enums = enumClass.getEnumConstants();            StringBuilder builder = new StringBuilder();            for (Enum en : enums) &#123;                if (en instanceof IEnum) &#123;                    var value = ReflectUtil.getFieldValue(en, &quot;value&quot;);                    var description = ReflectUtil.getFieldValue(en, &quot;description&quot;);                    builder.append(String.format(&quot;- %s: %s\\n&quot;, Convert.toStr(value), Convert.toStr(description)));                &#125;            &#125;            if (nextSchema != null &amp;&amp; !builder.isEmpty()) &#123;                nextSchema.setTitle(nextSchema.getDescription());                nextSchema.setDescription(builder.toString());            &#125;        &#125;        return nextSchema;    &#125;&#125;\n","categories":["技术"],"tags":["springdoc","swagger"]},{"title":"使用 systemctl 管理 SpringBoot 应用","url":"/2024/06/27/systemctl-spring-jar/","content":"/etc/systemd/system/my-application.service[Unit]Description=ApplicationName[Service]StartLimitInterval=5StartLimitBurst=10Restart=alwaysRestartSec=120StandardOutput=append:/data/project/logs/stdout.logStandardError=append:/data/project/logs/stderr.logWorkingDirectory=/opt/projectExecStart=/usr/local/java/jdk-21.0.3+9-jre/bin/java \\            -XX:+ExitOnOutOfMemoryError \\            -XX:+HeapDumpOnOutOfMemoryError \\            -XX:HeapDumpPath=/data/project/dumps/oom.bin \\            -Dspring.profiles.active= \\            -Dspring.config.location=classpath:application.yml,/opt/project/application.yml \\            -Dlogging.config=/opt/project/logback.xml \\            -jar /opt/project/project.jar[Install]WantedBy=multi-user.target\n\nsystemctl daemon-reloadsystemctl status my-application.service# 开机自启动systemctl enable my-application.service\n","categories":["技术"],"tags":["java","spring"]},{"title":"在 Prometheus 中使用钉钉机器人","url":"/2020/07/21/use-dingtalk-in-prometheus/","content":"启动 prometheus-webhook-dingtalk\n/data/prometheus-webhook-dingtalk/config/config.yml\n\ntimeout: 10sdefault_message:  title: &#x27;&#123;&#123; template &quot;legacy.title&quot; . &#125;&#125;&#x27;  text: &#x27;&#123;&#123; template &quot;legacy.content&quot; . &#125;&#125;&#x27;targets:  webhook1:    url: https://oapi.dingtalk.com/robot/send?access_token=xxx    secret: yyy    mention:      all: true\n\ndocker run -d \\    --name prometheus-webhook-dingtalk \\    --restart always \\    -p 8060:8060 \\    -v /data/prometheus-webhook-dingtalk/config:/etc/prometheus-webhook-dingtalk \\    timonwong/prometheus-webhook-dingtalk\n\n修改 prometheus 配置文件route:  receiver: &quot;dingtalk1&quot;receivers:- name: dingtalk1  webhook_configs:  - send_resolved: true    url: http://127.0.0.1:8060/dingtalk/webhook1/send\n\n参考\ntheo.im&#x2F;blog\n\ntimonwong&#x2F;prometheus-webhook-dingtalk\n\n\n","categories":["技术"],"tags":["prometheus","dingtalk"]},{"title":"使用 Grafana + Prometheus + Node-Exporter 监控机器","url":"/2020/04/26/use-grafana-monitor-vps/","content":"创建 Node-Exporter\nhttps://github.com/prometheus/node_exporter\n\ndocker run -d \\    --name node-exporter \\    --restart always \\    --net host \\    --pid host \\    -m 512m \\    -v /:/host:ro,rslave \\    prom/node-exporter:latest \\    --path.rootfs=/host\n\n创建 Prometheus\nhttps://github.com/prometheus/prometheus\n\n# prometheus.ymlglobal:  scrape_interval: 30s  evaluation_interval: 60sscrape_configs:  - job_name: &quot;prometheus&quot;    static_configs:      - targets:          - &quot;127.0.0.1:9090&quot;  - job_name: &quot;node&quot;    static_configs:      - targets:          - &quot;127.0.0.1:9100&quot;  # local          - &quot;127.0.0.2:9100&quot; # other\n\ndocker run -d \\    --name prometheus \\    --restart always \\    --user root \\    -p 9090:9090 \\    -m 2048m \\    -v /opt/docker/prometheus/config/prometheus.yml:/etc/prometheus/prometheus.yml \\    -v /opt/docker/prometheus/data:/prometheus \\    prom/prometheus:latest\n\n创建 Grafana\nhttps://github.com/grafana/grafana\n\ndocker run -d \\    --name grafana \\    --restart always \\    --user root \\    -p 3000:3000 \\    -v /opt/docker/grafana:/var/lib/grafana \\    grafana/grafana:latest\n\n配置 Grafana配置 DataSources在地址 &#123;$server_url&#125;/datasources/new 选择 Prometheus，在 URL 处填写地址。\n\n如果使用 docker 部署 Grafana，需通过宿主机访问 Prometheus，所以地址可能是 http://172.17.0.1:9090。\n\n导入 Dashboard\nhttps://grafana.com/grafana/dashboards/8919\n\n这里推荐使用上面的模版，在地址 &#123;$server_url&#125;/dashboard/import 输入 id 8919 然后保存即可。\n预览\n","categories":["技术"],"tags":["prometheus","grafana","vps"]},{"title":"使用 WinSW 部署 Windows Service","url":"/2020/05/29/use-winsw-to-deploy-windoes-service/","content":"安装\nwinsw&#x2F;winsw\n\n在 Release 页面下载最新版本以及示例配置文件。\n将可执行文件和配置文件都复制到自定义的目录，并将文件名改为一致。\n配置下面我使用 Frpc 作为演示。\n&lt;!-- frpc-service.xml --&gt;&lt;service&gt;    &lt;id&gt;frpc&lt;/id&gt;    &lt;name&gt;Frpc Service&lt;/name&gt;    &lt;description&gt;A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.&lt;/description&gt;    &lt;executable&gt;E:\\Frp\\frpc.exe&lt;/executable&gt;    &lt;onfailure action=&quot;restart&quot; delay=&quot;5 sec&quot; /&gt;    &lt;resetfailure&gt;1 day&lt;/resetfailure&gt;    &lt;arguments&gt;-c E:\\Frp\\frpc.ini&lt;/arguments&gt;    &lt;workingdirectory&gt;E:\\Frp&lt;/workingdirectory&gt;    &lt;priority&gt;AboveNormal&lt;/priority&gt;    &lt;stoptimeout&gt;15 sec&lt;/stoptimeout&gt;    &lt;stopparentprocessfirst&gt;false&lt;/stopparentprocessfirst&gt;    &lt;startmode&gt;Automatic&lt;/startmode&gt;    &lt;waithint&gt;15 sec&lt;/waithint&gt;    &lt;sleeptime&gt;1 sec&lt;/sleeptime&gt;    &lt;logpath&gt;E:\\Frp\\logs&lt;/logpath&gt;    &lt;log mode=&quot;roll-by-time&quot;&gt;        &lt;pattern&gt;yyyyMMdd&lt;/pattern&gt;    &lt;/log&gt;&lt;/service&gt;\n\n相关配置的解读请参考下载的示例配置文件。\n运行# 首先运行测试，看配置是否可以正常运行./frpc-service.exe testwait# 安装 Service./frpc-service.exe install# 运行 Service./frpc-service.exe start\n\n参考A wrapper binary that can be used to host executables as Windows servicesUsage: winsw [/redirect file] &lt;command&gt; [&lt;args&gt;]       Missing arguments trigger the service modeAvailable commands:  install     install the service to Windows Service Controller  uninstall   uninstall the service  start       start the service (must be installed before)  stop        stop the service  stopwait    stop the service and wait until it&#x27;s actually stopped  restart     restart the service  restart!    self-restart (can be called from child processes)  status      check the current status of the service  test        check if the service can be started and then stopped  testwait    starts the service and waits until a key is pressed then stops the service  version     print the version info  help        print the help info (aliases: -h,--help,-?,/?)Extra options:  /redirect   redirect the wrapper&#x27;s STDOUT and STDERR to the specified fileWinSW 2.9.0.0More info: https://github.com/kohsuke/winswBug tracker: https://github.com/kohsuke/winsw/issues\n","categories":["技术"],"tags":["windows","winsw"]},{"title":"win11 使用旧版右键菜单","url":"/2024/04/11/win11-use-old-right-click-menu/","content":"\n使用旧版\n\nreg add &quot;HKCU\\Software\\Classes\\CLSID\\&#123;86ca1aa0-34aa-4e8b-a509-50c905bae2a2&#125;\\InprocServer32&quot; /f /ve\n\n\n恢复新版\n\nreg delete &quot;HKCU\\Software\\Classes\\CLSID\\&#123;86ca1aa0-34aa-4e8b-a509-50c905bae2a2&#125;&quot; /f\n","categories":["技术"],"tags":["windows"]}]